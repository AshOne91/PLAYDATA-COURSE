### 🔍 **Softmax와 ReLU의 차이점 및 역할**  

| 활성화 함수 | 정의 | 사용 목적 | 출력 범위 |
|------------|------|----------|----------|
| **ReLU (Rectified Linear Unit)** | `f(x) = max(0, x)` | 은닉층 활성화 함수로 사용 | `[0, ∞]` |
| **Softmax** | `f(x_i) = exp(x_i) / Σ exp(x_j)` | 출력층에서 확률값 변환 | `[0, 1]`, 합이 1 |

---

### 🔷 **1️⃣ ReLU (Rectified Linear Unit)**
**✅ 정의:**  
ReLU는 입력 값이 0 이하일 때 0을 출력하고, 0보다 크면 그대로 출력하는 함수.

$$ f(x) = \max(0, x) $$

**✅ 특징:**  
- **비선형 함수:** 딥러닝 모델의 학습이 가능하게 만듦.  
- **기울기 소실(Vanishing Gradient) 문제 완화:**  
  - sigmoid나 tanh와 달리, 양수 입력에서 기울기가 1로 유지되므로 역전파 시 학습이 원활함.  
- **음수 입력에서 뉴런 죽음(Dead Neuron) 문제:**  
  - 입력이 0 이하일 경우 기울기가 0이 되어 학습이 멈춤.  

**✅ 사용처:**  
- **은닉층 활성화 함수**로 사용됨.  
- CNN, RNN, MLP 등 대부분의 신경망에서 기본 활성화 함수로 활용됨.

---

### 🔷 **2️⃣ Softmax**
**✅ 정의:**  
Softmax는 여러 개의 출력을 **확률 분포 형태**로 변환하는 함수.

$$ f(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}} $$

**✅ 특징:**  
- **출력값을 0~1 사이로 정규화**  
- **출력값들의 합이 1이 됨** → 확률적인 해석 가능  
- **Logits 값을 확률로 변환**하여 다중 분류에서 사용됨  

**✅ 사용처:**  
- **출력층에서 다중 분류 문제**(예: `softmax` → `categorical_crossentropy` 손실함수)  

---

### 🔍 **📌 ReLU와 Softmax의 차이점**
| 비교 항목 | ReLU | Softmax |
|----------|------|---------|
| 역할 | 은닉층 활성화 | 출력층 활성화 |
| 수식 | `max(0, x)` | `exp(x) / sum(exp(x))` |
| 사용 위치 | 은닉층 | 출력층 (다중 분류) |
| 주요 특징 | 비선형성 제공, 기울기 소실 해결 | 확률값 변환 |

---

### 🛠 **실제 코드 예제**
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 모델 생성
model = Sequential([
    Dense(128, activation='relu', input_shape=(10,)),  # 은닉층: ReLU
    Dense(64, activation='relu'),  # 은닉층: ReLU
    Dense(3, activation='softmax')  # 출력층: Softmax (다중 분류)
])

# 모델 컴파일
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()
```
- 은닉층에서는 `ReLU` 사용 → **특징 추출 & 비선형성 부여**
- 출력층에서는 `Softmax` 사용 → **확률값으로 변환 (다중 분류)**

---

### ✅ **결론**
- **ReLU**: 은닉층에서 사용, 0 이상의 값만 활성화 (학습 안정성 증가).  
- **Softmax**: 출력층에서 사용, 확률값으로 변환 (다중 클래스 분류).  

따라서, **ReLU는 신경망 내부에서 정보 전달을 원활하게 하고, Softmax는 최종 출력을 확률로 변환하여 해석 가능하게 만드는 역할을 함.** 🚀

### 🔍 **합성곱(Convolution)이란?**
합성곱(Convolution)은 **특징을 추출하는 연산**으로, CNN(Convolutional Neural Network)에서 핵심적으로 사용됨.  
입력 데이터(이미지)에서 중요한 패턴을 찾아내고, 차원을 줄이면서 의미 있는 특징을 유지하는 역할을 함.  

---

### 🔷 **1️⃣ 합성곱 연산 (Convolution Operation)**
✅ **정의:**  
합성곱 연산은 **커널(필터, Kernel)을 이용해 입력 데이터를 스캔하면서 특징을 추출하는 과정**.  
커널은 작은 행렬(예: 3×3, 5×5)로, 이미지의 특정 패턴(엣지, 모서리, 텍스처 등)을 감지하는 역할을 함.  

✅ **수식:**  
주어진 입력 데이터 \( I \)와 커널 \( K \)의 합성곱은 다음과 같이 계산됨.

$$ (I * K)(x, y) = \sum_{i} \sum_{j} I(x+i, y+j) \cdot K(i, j) $$

✅ **예제:**  
(3×3 필터를 사용한 합성곱 연산 예시)

입력 행렬 (5×5)  
\[
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 \\
4 & 5 & 6 & 1 & 2 \\
7 & 8 & 9 & 2 & 3 \\
1 & 2 & 3 & 0 & 1 \\
4 & 5 & 6 & 1 & 2
\end{bmatrix}
\]

필터(커널) (3×3)  
\[
\begin{bmatrix}
1 & 0 & -1 \\
1 & 0 & -1 \\
1 & 0 & -1
\end{bmatrix}
\]

이 필터를 왼쪽 위부터 오른쪽 아래까지 이동하면서 곱하고 합하면 출력 행렬이 생성됨.

✅ **주요 개념**
- **Stride (스트라이드):** 필터가 이동하는 간격 (보통 1 또는 2)
- **Padding (패딩):** 경계를 처리하기 위해 0을 추가하는 기법 (SAME vs. VALID)
- **Feature Map:** 합성곱 연산 결과로 얻어진 출력 데이터

---

### 🔷 **2️⃣ 합성곱 층 (Convolutional Layer)**
✅ **구성 요소:**  
1. **입력 데이터** (이미지, 텐서 형태)  
2. **필터(커널)** (가중치 학습)  
3. **활성화 함수** (주로 ReLU 사용)  
4. **출력 특징 맵** (Feature Map)  

✅ **예제 코드 (TensorFlow/Keras)**
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),  # 3×3 필터 32개 적용
    MaxPooling2D((2,2)),  # 2×2 풀링
])

model.summary()
```
- `Conv2D(32, (3,3), activation='relu')` → 3×3 필터 32개 적용
- `MaxPooling2D((2,2))` → 2×2 영역에서 최대값만 추출 (차원 축소)

---

### 🔷 **3️⃣ 합성곱의 장점**
✅ **파라미터 수 감소:**  
  - 완전연결 신경망보다 적은 가중치를 사용하여 학습 가능.  

✅ **공간적 구조 유지:**  
  - 이미지의 위치적 특성을 유지하면서 학습 가능.  

✅ **특징 자동 추출:**  
  - 필터가 데이터에서 의미 있는 특징을 자동으로 학습.  

✅ **변환에 강함 (Translation Invariance):**  
  - 동일한 패턴이 위치를 달리해도 학습 가능.  

---

### ✅ **결론**
- **합성곱은 CNN에서 특징을 추출하는 핵심 연산**.
- **커널(필터)을 사용하여 입력을 스캔하며, 유용한 패턴을 찾음**.
- **ReLU와 풀링(MaxPooling)과 함께 사용하여 성능을 최적화**. 🚀

### 🔍 **특성 맵(Feature Map)이란?**  
**특성 맵(Feature Map)**은 CNN(합성곱 신경망)에서 **합성곱 연산을 통해 추출된 특징(Feature)을 담고 있는 출력 행렬**을 의미함.  
이미지 내 엣지, 패턴, 질감 등 중요한 정보가 반영된 데이터로, **입력 이미지보다 작은 크기**로 나타나는 경우가 많음.  

---

### 🔷 **1️⃣ 특성 맵 생성 과정**  
특성 맵은 **합성곱 연산(Convolution) → 활성화 함수(ReLU) → 풀링(Pooling)** 과정을 거쳐 생성됨.  

✅ **특성 맵 생성 흐름**  
1. **입력 이미지** → (CNN 입력)  
2. **합성곱 연산(Conv2D) → 필터(커널) 적용**  
3. **ReLU 활성화 함수 적용**  
4. **풀링(Pooling)으로 차원 축소**  
5. **특성 맵(Feature Map) 생성**  

---

### 🔷 **2️⃣ 특성 맵 예제**
#### 📌 **예제 1: 합성곱 연산 후 특성 맵 생성**  
예를 들어, 5×5 입력 이미지에 **3×3 필터(커널)** 을 적용하는 경우:

✅ **입력 이미지 (5×5)**  
\[
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 \\
4 & 5 & 6 & 1 & 2 \\
7 & 8 & 9 & 2 & 3 \\
1 & 2 & 3 & 0 & 1 \\
4 & 5 & 6 & 1 & 2
\end{bmatrix}
\]

✅ **필터(커널) (3×3)**  
\[
\begin{bmatrix}
1 & 0 & -1 \\
1 & 0 & -1 \\
1 & 0 & -1
\end{bmatrix}
\]

✅ **특성 맵(Feature Map) (3×3) 출력 예시**  
\[
\begin{bmatrix}
X & X & X \\
X & X & X \\
X & X & X
\end{bmatrix}
\]
- `X`는 합성곱 연산을 거친 값 (특징이 강조됨)

---

### 🔷 **3️⃣ 특성 맵의 주요 특징**
✅ **패턴 강조:**  
  - 필터(커널) 연산을 통해 **엣지(경계), 텍스처, 모양** 등의 특징이 강조됨.  

✅ **차원 축소:**  
  - 필터 크기(예: 3×3)와 스트라이드 설정에 따라 원본보다 크기가 작아질 수 있음.  
  - 하지만 패딩(SAME padding)을 사용하면 크기를 유지할 수도 있음.  

✅ **다중 필터 적용 가능:**  
  - 한 층에서 여러 개의 필터(커널)를 사용하면 **여러 개의 특성 맵이 생성됨.**  
  - 예: 32개의 필터 사용 → 32개의 특성 맵 생성  

---

### 🔷 **4️⃣ 특성 맵 예제 코드 (TensorFlow/Keras)**
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten

# CNN 모델 생성
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),  # 32개 특성 맵 생성
    MaxPooling2D((2,2)),  # 2×2 풀링으로 차원 축소
])

# 모델 구조 출력
model.summary()
```
**📌 실행 결과 예시:**  
```plaintext
Layer (type)           Output Shape       Param #   
---------------------------------------------------
conv2d (Conv2D)        (None, 26, 26, 32)  320      
max_pooling2d (MaxPool (None, 13, 13, 32)  0        
---------------------------------------------------
```
- `(None, 26, 26, 32)`: **32개의 특성 맵이 생성됨.**  
- `(None, 13, 13, 32)`: **풀링으로 크기가 절반으로 줄어듦.**  

---

### ✅ **결론**
- **특성 맵(Feature Map)**은 CNN에서 **필터(커널)를 통해 입력 데이터에서 중요한 특징을 추출한 결과**임.  
- **CNN의 여러 계층에서 점점 더 고차원의 특징을 학습**하면서, 초기엔 엣지/패턴을 감지하고, 이후엔 객체 형태를 파악함.  
- 특성 맵의 개수는 필터(커널) 개수에 따라 결정되며, 풀링을 통해 크기를 줄일 수 있음. 🚀

### 🔍 **패딩(Padding)의 목적**  
패딩(Padding)은 **합성곱 연산(Convolution) 시 입력 데이터의 경계를 처리하기 위해 0을 추가하는 기법**임.  
이를 통해 **출력 크기를 조절하고, 중요한 정보를 유지할 수 있음.**  

---

### 🔷 **1️⃣ 패딩의 주요 목적**
✅ **출력 크기 유지 (Output Size Preservation)**  
  - 필터를 적용하면 출력 크기가 줄어드는데, 패딩을 사용하면 **입력과 동일한 크기를 유지 가능**.  
  - 특히 깊은 신경망에서는 크기 감소가 누적되므로, 패딩이 필수적임.  

✅ **경계 정보 손실 방지 (Prevent Information Loss at Borders)**  
  - 필터가 중앙보다 가장자리 부분에서 연산할 기회가 적음.  
  - 패딩을 하면 **경계 부분의 정보도 학습에 반영될 수 있음.**  

✅ **특성 맵 크기 제어 (Control Feature Map Size)**  
  - 패딩을 조절하여 **네트워크 깊이에 따른 크기 감소를 방지**할 수 있음.  
  - 특히, 딥러닝 모델에서는 크기 감소가 너무 빠르게 일어나면 정보 손실이 큼.  

✅ **연산 최적화 (Better Convolution Efficiency)**  
  - 특정 크기(예: 2의 거듭제곱)로 맞추면 GPU 연산이 더 효율적일 수 있음.  

---

### 🔷 **2️⃣ 패딩 종류**
패딩 방식에 따라 CNN의 출력 크기와 특성이 달라짐.  

| 패딩 방식 | 설명 | 출력 크기 변화 |
|-----------|------------------|----------------|
| **VALID** 패딩 | 패딩 없음. 경계에서 크기 감소. | **작아짐** |
| **SAME** 패딩 | 출력 크기를 입력 크기와 동일하게 유지. | **유지됨** |

---

### 🔷 **3️⃣ 패딩 연산 예제**
#### ✅ **(1) VALID 패딩 (패딩 없음)**
패딩 없이 \(3 \times 3\) 필터를 \(5 \times 5\) 입력에 적용하면:

\[
\text{출력 크기} = (5 - 3) + 1 = 3
\]

출력 크기: \(3 \times 3\)  

---

#### ✅ **(2) SAME 패딩 (출력 크기 유지)**
입력과 동일한 크기를 유지하려면 **패딩 추가** 필요.  

패딩 추가 후:  
\[
\text{출력 크기} = \frac{(5 - 3 + 2P)}{S} + 1
\]

출력 크기 유지 → \(P = 1\) 필요 (1픽셀씩 패딩 추가)  
즉, **입력 크기를 유지하면서 필터 적용 가능**.  

---

### 🔷 **4️⃣ 패딩 예제 코드 (TensorFlow/Keras)**
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D

model = Sequential([
    Conv2D(32, (3,3), activation='relu', padding='valid', input_shape=(28,28,1)),  # VALID 패딩 (크기 줄어듦)
    Conv2D(64, (3,3), activation='relu', padding='same')  # SAME 패딩 (크기 유지)
])

model.summary()
```
**📌 실행 결과 예시**
```plaintext
Layer (type)           Output Shape        Param #   
----------------------------------------------------
conv2d (Conv2D)        (None, 26, 26, 32)  320      
conv2d_1 (Conv2D)      (None, 26, 26, 64)  18496    
----------------------------------------------------
```
- 첫 번째 `Conv2D` → VALID 패딩 → 크기 감소 (\(28 \to 26\))  
- 두 번째 `Conv2D` → SAME 패딩 → 크기 유지 (\(26 \to 26\))  

---

### ✅ **결론**
- **VALID 패딩:** 패딩 없음, 출력 크기 감소  
- **SAME 패딩:** 입력 크기 유지, 경계 정보 보존  
- CNN에서 패딩을 적절히 조절하여 **특성 맵 크기를 조절하고 정보 손실을 방지할 수 있음.** 🚀

### 🔍 **스트라이드(Stride)란?**  
**스트라이드(Stride)**는 **필터(커널)가 이동하는 간격(픽셀 수)**을 의미함.  
기본적으로 **스트라이드가 1이면 한 픽셀씩 이동하고, 스트라이드가 2 이상이면 더 크게 이동**함.  
스트라이드는 **출력 크기와 연산량에 영향을 미침.**  

---

### 🔷 **1️⃣ 스트라이드의 동작 방식**  
✅ **기본 개념**  
- 입력 데이터에 필터(커널)를 적용할 때, **스트라이드가 1이면 한 칸씩 이동**,  
  스트라이드가 2면 **두 칸씩 이동**하여 연산 수행.  
- **스트라이드 값이 클수록 특성 맵 크기가 작아지고, 연산량이 감소함.**  

✅ **출력 크기 계산 공식**  
\[
\text{출력 크기} = \frac{\text{(입력 크기 - 필터 크기) + 2P}}{S} + 1
\]
- \(P\) = 패딩 크기  
- \(S\) = 스트라이드 크기  

---

### 🔷 **2️⃣ 스트라이드 예제**
#### ✅ **(1) 스트라이드 1 (S=1, 기본값)**
- 필터가 **한 픽셀씩 이동**  
- 입력 크기: \(5 \times 5\), 필터 크기: \(3 \times 3\)  
- 출력 크기: \( (5-3)/1 + 1 = 3 \)  
- **출력 크기: \(3 \times 3\)**  

#### ✅ **(2) 스트라이드 2 (S=2, 간격 증가)**
- 필터가 **두 픽셀씩 이동**  
- 입력 크기: \(5 \times 5\), 필터 크기: \(3 \times 3\)  
- 출력 크기: \( (5-3)/2 + 1 = 2 \)  
- **출력 크기: \(2 \times 2\)**  

#### ✅ **(3) 스트라이드 3 (S=3)**
- 필터가 **세 픽셀씩 이동**  
- 입력 크기: \(5 \times 5\), 필터 크기: \(3 \times 3\)  
- 출력 크기: \( (5-3)/3 + 1 = 1.33 \) → 정수로 반올림 → **출력 크기: \(2 \times 2\)**  

---

### 🔷 **3️⃣ 스트라이드와 패딩 조합**
✅ **SAME 패딩 + 스트라이드 1**  
- 크기 유지 가능  
- `padding='same'` 옵션 사용  

✅ **VALID 패딩 + 스트라이드 2**  
- 출력 크기 급격히 감소  
- 연산량 감소  

✅ **스트라이드 값이 커지면?**  
- 특성 맵 크기 축소됨 → **공간 정보 손실**  
- 연산량 감소 → **빠른 학습 가능**  

---

### 🔷 **4️⃣ 스트라이드 적용 예제 코드 (TensorFlow/Keras)**
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D

model = Sequential([
    Conv2D(32, (3,3), strides=1, activation='relu', padding='same', input_shape=(28,28,1)),  # 기본값
    Conv2D(64, (3,3), strides=2, activation='relu', padding='valid'),  # 스트라이드 2 적용
])

model.summary()
```
**📌 실행 결과 예시**
```plaintext
Layer (type)           Output Shape        Param #   
----------------------------------------------------
conv2d (Conv2D)        (None, 28, 28, 32)   320      
conv2d_1 (Conv2D)      (None, 13, 13, 64)   18496    
----------------------------------------------------
```
- 첫 번째 `Conv2D` → 스트라이드 1, 크기 유지  
- 두 번째 `Conv2D` → 스트라이드 2, 크기 감소 \(28 \to 13\)  

---

### ✅ **결론**
- **스트라이드(Stride)는 필터가 이동하는 간격을 의미**하며, 연산량과 특성 맵 크기에 영향을 줌.  
- **스트라이드가 커지면 출력 크기가 작아지고 연산량이 줄어듦.**  
- CNN에서 **특성 추출과 연산 최적화를 위해 스트라이드를 조절하여 사용함.** 🚀

### 📌 **CNN(합성곱 신경망) 개념 학습 흐름 & 예제**  
CNN을 이해하기 위해 **입력 → 합성곱 → 활성화 함수 → 풀링 → 출력**의 흐름을 따라 예제를 살펴보겠음.  

---

## **🟢 1️⃣ 데이터 입력**
CNN은 **이미지 데이터를 입력으로 받음.**  
일반적으로 **가로 × 세로 × 채널(RGB)** 형식으로 표현됨.  

✅ **예제: 6×6 흑백 이미지 데이터**  
(값은 픽셀의 밝기 정도를 의미함)  
```
6   2   1   3   2   0  
5   3   2   4   1   1  
4   2   1   5   3   2  
2   1   0   3   4   6  
3   2   1   4   5   2  
1   0   2   6   3   1  
```
- **입력 크기:** \(6 \times 6 \times 1\) (흑백이라 채널 1개)  
- CNN은 이 데이터를 받아 **특징을 추출하고 분류 수행**  

---

## **🔵 2️⃣ 합성곱 연산 (Convolution)**
합성곱은 **필터(커널)를 이용하여 이미지 특징을 추출**하는 과정임.  

✅ **예제: 3×3 필터 적용**  
```
1   0  -1  
1   0  -1  
1   0  -1  
```
- **필터 크기:** \(3 \times 3\)  
- **스트라이드 1 (한 칸씩 이동)**  
- **패딩 없음 (VALID 패딩, 크기 감소됨)**  

💡 **첫 번째 연산 과정**
```
(6×1) + (2×0) + (1×-1)  
+ (5×1) + (3×0) + (2×-1)  
+ (4×1) + (2×0) + (1×-1)  
= 6 + 0 -1 + 5 + 0 -2 + 4 + 0 -1  
= **11**
```
이렇게 **각 위치에서 합성곱 연산을 수행하여 특성 맵을 생성함.**  

---

## **🟠 3️⃣ 활성화 함수 (ReLU) 적용**
ReLU(Rectified Linear Unit)는 **비선형성을 추가하여 신경망이 복잡한 패턴을 학습할 수 있도록 함.**  
- \(\text{ReLU}(x) = \max(0, x)\)  
- 음수 값을 0으로 변경하여 **특징을 강조**함.  

✅ **예제 적용 (ReLU 연산)**
```
11   -2   5   -3  
2   -5   8   -1  
0   -4   6   -2  
7   -3   1   -1  
```
**ReLU 적용 후**
```
11   0   5   0  
2    0   8   0  
0    0   6   0  
7    0   1   0  
```
- 음수 값이 **모두 0으로 변환됨**  
- **특성 맵에서 중요한 부분만 남음**  

---

## **🟣 4️⃣ 풀링 (Max Pooling)**
풀링(Pooling)은 **특성 맵의 크기를 줄이고 중요한 특징만 남기는 과정**임.  
- **최대 풀링(Max Pooling): 특정 영역 내 최댓값 선택**  
- **2×2 필터, 스트라이드 2 적용**  

✅ **예제 적용 (2×2 최대 풀링)**
```
11   0   5   0  
2    0   8   0  
0    0   6   0  
7    0   1   0  
```
**풀링 결과**
```
11   8  
7    6  
```
- 크기: \(4 \times 4 \to 2 \times 2\)로 축소됨  
- 중요한 특징만 유지됨  

---

## **🔴 5️⃣ 완전 연결층 (Fully Connected Layer)**
CNN이 최종적으로 **출력값을 분류하기 위해 완전 연결층(Dense Layer)에 전달**함.  
이후 **Softmax 함수**를 적용하여 **확률 값으로 변환**함.  

✅ **출력 예제**
```
[0.1, 0.7, 0.2]  → 클래스 1이 70% 확률로 예측됨
```
- Softmax는 **출력값을 확률로 변환하여 최종 분류** 수행  

---

## **💡 전체 과정 코드 구현 (TensorFlow/Keras)**
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# CNN 모델 생성
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(6,6,1)),  # 6×6 흑백 이미지
    MaxPooling2D(pool_size=(2,2)),  # 2×2 최대 풀링
    Flatten(),  # 1D 벡터 변환
    Dense(10, activation='softmax')  # 출력층 (10개 클래스)
])

model.summary()
```
**📌 실행 결과 예시**
```plaintext
Layer (type)           Output Shape        Param #   
----------------------------------------------------
conv2d (Conv2D)        (None, 4, 4, 32)    320      
max_pooling2d (MaxPool (None, 2, 2, 32)    0        
flatten (Flatten)      (None, 128)         0        
dense (Dense)          (None, 10)          1290     
----------------------------------------------------
```
- **합성곱 연산 후**: \(4 \times 4 \times 32\) 특성 맵 생성  
- **풀링 후**: \(2 \times 2 \times 32\)로 축소  
- **완전 연결층(Flatten) 후**: \(128\) 차원 벡터로 변환  
- **출력층(Dense Layer) 후**: \(10\)개 클래스 확률 출력  

---

## **✅ CNN 흐름 정리**
| 단계 | 설명 | 예제 |
|------|-----------------|----------------------|
| **입력 데이터** | 이미지 입력 | \(6 \times 6 \) 행렬 |
| **합성곱 (Convolution)** | 필터 적용 → 특징 추출 | \(3 \times 3\) 필터 사용 |
| **활성화 함수 (ReLU)** | 비선형성 추가 | 음수 제거 (ReLU) |
| **풀링 (Max Pooling)** | 크기 축소 | 2×2 필터로 다운샘플링 |
| **완전 연결층 (FC Layer)** | 벡터 변환 후 예측 | Softmax로 확률 출력 |

CNN은 이 과정을 반복하면서 **더 깊은 네트워크를 학습하고, 이미지 분류를 수행함.** 🚀
일차원으로 펼치기 위해




