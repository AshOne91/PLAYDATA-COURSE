**1. XGBoost Classification**  
   - 설명: Gradient Boosting을 기반으로 한 강력한 분류 알고리즘. 속도가 빠르고 성능이 우수함.  
   - 예제: `from xgboost import XGBClassifier`  
     ```python
     model = XGBClassifier()
     model.fit(X_train, y_train)
     y_pred = model.predict(X_test)
     ```
   - 예시: 신용카드 부정 사용 탐지  

**2. Support Vector Classification (SVC)**  
   - 설명: 초평면을 사용하여 데이터를 분류하는 SVM 기반 알고리즘.  
   - 예제: `from sklearn.svm import SVC`  
     ```python
     model = SVC()
     model.fit(X_train, y_train)
     y_pred = model.predict(X_test)
     ```
   - 예시: 스팸 이메일 분류  

**3. Random Forest Classification**  
   - 설명: 여러 개의 결정 트리를 결합하여 과적합을 방지하고 성능을 향상시키는 앙상블 학습법.  
   - 예제: `from sklearn.ensemble import RandomForestClassifier`  
     ```python
     model = RandomForestClassifier()
     model.fit(X_train, y_train)
     y_pred = model.predict(X_test)
     ```
   - 예시: 의료 진단 시스템  

**4. Neural Network Classification**  
   - 설명: 인공 신경망을 이용한 분류 모델. 복잡한 패턴을 학습할 수 있음.  
   - 예제: `from tensorflow.keras.models import Sequential`  
     ```python
     model = Sequential([
         Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
         Dense(1, activation='sigmoid')
     ])
     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
     model.fit(X_train, y_train, epochs=10)
     ```
   - 예시: 얼굴 인식  

**5. Logistic Regression**  
   - 설명: 이진 분류 문제에서 널리 사용되는 선형 모델.  
   - 예제: `from sklearn.linear_model import LogisticRegression`  
     ```python
     model = LogisticRegression()
     model.fit(X_train, y_train)
     y_pred = model.predict(X_test)
     ```
   - 예시: 고객 이탈 예측  
