### **📌 결측치(Missing Values) 처리: 제거 vs. 대체**  

데이터의 결측치 처리는 데이터 타입(수치형 vs. 범주형)과 데이터의 특성에 따라 **제거(drop)** 또는 **대체(impute)** 방식을 선택해야 합니다.  

---

## **1️⃣ 결측치 제거 (Drop)**
💡 **언제 제거해야 할까?**  
- 결측치가 포함된 행(row)이 전체 데이터에서 **차지하는 비율이 적을 때** (예: 5% 미만)  
- 해당 컬럼이 **분석에 큰 영향을 미치지 않을 때**  
- 결측치가 특정 패턴 없이 **무작위로 발생했을 때 (MCAR; Missing Completely at Random)**  
- **대체할 적절한 값이 없거나** 대체 시 **데이터 왜곡 가능성이 높을 때**  

🔹 **예제 (Pandas)**
```python
df.dropna(subset=['컬럼명'], inplace=True)  # 특정 컬럼 기준으로 결측치가 있는 행 삭제
```

---

## **2️⃣ 결측치 대체 (Impute)**
💡 **언제 대체해야 할까?**  
- **결측치가 많은 경우** (행을 제거하면 데이터 손실이 크기 때문)  
- 해당 컬럼이 **중요한 정보**를 포함하고 있을 때  
- 결측치가 특정 패턴을 보일 가능성이 있을 때 (MAR, MNAR)  
- 데이터 손실을 최소화하고 모델 성능을 유지하고 싶을 때  

---

# **📌 데이터 타입별 결측치 처리 방법**
## **✅ 수치형 데이터 (int, float)**
### **1️⃣ 제거 (Drop)**
- 결측 데이터 비율이 낮고, 제거해도 데이터 손실이 크지 않을 때  
```python
df.dropna(subset=['수치형컬럼'], inplace=True)  
```

### **2️⃣ 대체 (Impute)**
#### **✔ 평균(mean) 대체**
📌 **정규 분포를 따르는 데이터에 적합**  
```python
df['수치형컬럼'].fillna(df['수치형컬럼'].mean(), inplace=True)
```

#### **✔ 중앙값(median) 대체**
📌 **이상치(outlier)가 많은 경우 적합 (ex: 소득, 주택 가격)**  
```python
df['수치형컬럼'].fillna(df['수치형컬럼'].median(), inplace=True)
```

#### **✔ 최빈값(mode) 대체**
📌 **값이 특정 값에 집중되어 있을 때 사용 가능**  
```python
df['수치형컬럼'].fillna(df['수치형컬럼'].mode()[0], inplace=True)
```

#### **✔ KNN 또는 머신러닝을 이용한 예측 대체**
📌 **다른 변수들과의 관계를 활용해 결측치를 보완할 때 사용**  
```python
from sklearn.impute import KNNImputer
imputer = KNNImputer(n_neighbors=5)  # 가장 가까운 5개의 값 평균 사용
df[['수치형컬럼']] = imputer.fit_transform(df[['수치형컬럼']])
```

#### **✔ 앞/뒤 값 채우기 (시계열 데이터)**
📌 **시간 순서가 있는 데이터 (ex: 주가, 기온, 센서 데이터)에서 사용**  
```python
df['수치형컬럼'].fillna(method='ffill', inplace=True)  # 이전 값으로 채우기
df['수치형컬럼'].fillna(method='bfill', inplace=True)  # 다음 값으로 채우기
```

---

## **✅ 범주형 데이터 (object, category)**
### **1️⃣ 제거 (Drop)**
- 결측치 비율이 적고, 해당 컬럼이 분석에 크게 영향을 미치지 않을 때  
```python
df.dropna(subset=['범주형컬럼'], inplace=True)
```

### **2️⃣ 대체 (Impute)**
#### **✔ 최빈값(mode) 대체**
📌 **범주형 데이터에서 가장 많이 등장한 값으로 채움**  
```python
df['범주형컬럼'].fillna(df['범주형컬럼'].mode()[0], inplace=True)
```

#### **✔ ‘Unknown’ 또는 ‘Other’ 등 특정 값 대체**
📌 **카테고리가 명확하지 않거나, 분석에서 큰 영향이 없을 때**  
```python
df['범주형컬럼'].fillna('Unknown', inplace=True)
```

#### **✔ 그룹별 최빈값 대체**
📌 **특정 그룹(예: 지역, 성별 등)에 따라 결측치를 보완해야 할 때**  
```python
df['범주형컬럼'] = df.groupby('기준컬럼')['범주형컬럼'].transform(lambda x: x.fillna(x.mode()[0]))
```

#### **✔ 예측 모델 활용 (ML Imputation)**
📌 **다른 변수들과의 관계를 활용해 결측치를 보완할 때 사용**  
```python
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="most_frequent")
df[['범주형컬럼']] = imputer.fit_transform(df[['범주형컬럼']])
```

---

# **3️⃣ 결론: 수치형 vs 범주형 비교 정리**
| 데이터 타입 | 제거 (Drop) | 대체 (Impute) |
|------------|------------|---------------|
| **수치형** | 결측치 비율이 낮거나 데이터 왜곡 우려가 클 때 | 평균, 중앙값, KNN, 시계열 보간 사용 |
| **범주형** | 결측치 비율이 낮거나 의미 없는 컬럼일 때 | 최빈값, 'Unknown' 대체, 그룹별 보완 |

✅ **수치형은 평균·중앙값·KNN 등 수치적 방법 활용**  
✅ **범주형은 최빈값, 특정 값 ('Unknown') 활용**  
✅ **데이터 특성을 고려해 최적의 방법 선택**  

---

## **📌 결측치 처리 방법 선택 기준**
| 상황 | 제거 (Drop) | 대체 (Impute) |
|------|------------|---------------|
| 결측 데이터 비율 | 적을 때 (5% 미만) | 많을 때 (5% 이상) |
| 데이터 손실 우려 | 적음 | 큼 |
| 해당 컬럼 중요도 | 낮음 | 높음 |
| 데이터 패턴 고려 | 무작위 (MCAR) | 특정 패턴 (MAR, MNAR) |
| 머신러닝 모델 적용 | 필요 없음 | 필요할 수 있음 |

---

## **📌 타이타닉 데이터셋 이상치 분석 – 수학적 개념 정리**  
이상치 분석에서 핵심이 되는 **IQR (사분위수 범위)**, **Z-score (표준점수)** 개념을 수학적으로 설명하고, 코드와 함께 이해해보자.  

---

# **1️⃣ 이상치란?**  
이상치는 **데이터 분포에서 비정상적으로 크거나 작은 값**을 의미해.  
이상치는 분석을 방해하거나 잘못된 결과를 초래할 수 있기 때문에 **제거 또는 변환이 필요**해.  

이상치를 판별하는 대표적인 방법은 두 가지야:  
1️⃣ **IQR (Interquartile Range, 사분위수 범위)**  
2️⃣ **Z-score (표준점수, 정규화된 거리)**  

---

# **2️⃣ IQR (사분위수 범위) 방법 – 상위/하위 1.5배 판별법**  
## **✔ IQR 개념**  
IQR(Interquartile Range)은 **데이터의 중앙 50%를 포함하는 범위**야.  
이걸 활용해서 이상치를 판별하는 기준은 아래와 같아.

### **📌 IQR 계산 공식**
\[
IQR = Q3 - Q1
\]
- **Q1 (제1사분위, 25%)**: 데이터의 하위 25% 지점 값  
- **Q3 (제3사분위, 75%)**: 데이터의 상위 25% 지점 값  
- **IQR (사분위수 범위)**: Q3 - Q1  

### **📌 이상치 기준**
이상치는 **Q1 - 1.5 × IQR** 미만이거나 **Q3 + 1.5 × IQR** 초과하는 값으로 정해.  
\[
\text{Lower Bound} = Q1 - 1.5 \times IQR
\]
\[
\text{Upper Bound} = Q3 + 1.5 \times IQR
\]

---

## **✔ IQR 코드 예제**
```python
import pandas as pd
import numpy as np

# 데이터 불러오기
df = pd.read_csv("titanic.csv")

# IQR을 이용한 이상치 탐색 함수
def find_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)  # 제1사분위
    Q3 = df[column].quantile(0.75)  # 제3사분위
    IQR = Q3 - Q1  # IQR 계산
    lower_bound = Q1 - 1.5 * IQR  # 하한
    upper_bound = Q3 + 1.5 * IQR  # 상한
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]  # 이상치 찾기
    
    print(f"📌 [{column}의 이상치 개수]: {len(outliers)}개")
    return outliers

# 이상치 확인 (나이, 요금 등)
find_outliers_iqr(df, "Fare")
```
✅ **해석:**  
- `Fare` 같은 경우 높은 티켓 가격이 많아서 이상치로 판별될 가능성이 커!  
- `Age` 같은 경우 상대적으로 이상치가 적을 수도 있어.  

---

# **3️⃣ Z-score (표준점수) 방법 – 평균과 표준편차 기준**
## **✔ Z-score 개념**  
Z-score는 **데이터 값이 평균으로부터 얼마나 떨어져 있는지를 표준편차 기준으로 측정하는 값**이야.

### **📌 Z-score 공식**
\[
Z = \frac{X - \mu}{\sigma}
\]
- \(X\) : 특정 데이터 값  
- \(\mu\) : 데이터의 평균  
- \(\sigma\) : 데이터의 표준편차  

### **📌 이상치 기준**
이상치는 **Z-score가 ±3을 초과하는 값**으로 간주해.  
\[
|Z| > 3
\]
즉, 평균에서 3 표준편차 이상 벗어난 값들은 이상치일 확률이 높아.

---

## **✔ Z-score 코드 예제**
```python
from scipy import stats

# Z-score 기반 이상치 탐색
def find_outliers_zscore(df, column):
    z_scores = np.abs(stats.zscore(df[column].dropna()))  # Z-score 계산
    outliers = df[z_scores > 3]  # |Z| > 3인 값 찾기
    print(f"📌 [{column}의 이상치 개수]: {len(outliers)}개")
    return outliers

# 이상치 확인
find_outliers_zscore(df, "Fare")
```
✅ **해석:**  
- `Fare`의 경우, 평균에서 3배 이상 벗어난 값들은 이상치로 판별됨.  
- `Age`처럼 정규분포를 따르는 컬럼에서는 이상치가 적을 수도 있어.

---

# **4️⃣ 이상치 처리 방법**
이제 **이상치를 어떻게 처리할지** 결정해야 해.

| 방법 | 설명 | 코드 |
|------|------|------|
| **제거 (Remove)** | 이상치가 너무 많거나 중요하지 않다면 삭제 | `df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]` |
| **대체 (Replace)** | 이상치를 평균, 중앙값 등으로 변경 | `df[col] = np.clip(df[col], lower_bound, upper_bound)` |
| **로그 변환 (Log Transform)** | 이상치가 큰 경우 로그 변환으로 완화 | `df['col'] = np.log1p(df['col'])` |

---

## **① 이상치 제거 (IQR 기준)**
```python
# IQR 기반 이상치 제거
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

df_clean = remove_outliers(df, 'Fare')
print(f"✅ 이상치 제거 후 데이터 크기: {df_clean.shape}")
```
✅ **해석:**  
- `Fare`의 이상치를 제거하여 데이터 크기가 줄어들었음을 확인할 수 있음.

---

## **② 이상치 대체 (클리핑)**
```python
# 이상치를 상한/하한 값으로 변환
df['Fare'] = np.clip(df['Fare'], df['Fare'].quantile(0.05), df['Fare'].quantile(0.95))
```
✅ **해석:**  
- `Fare`에서 극단적인 이상치를 **상위 95%, 하위 5% 백분위 값으로 제한**하여 왜곡을 줄임.

---

## **③ 로그 변환 (분포 조정)**
```python
# Fare 로그 변환
df['Fare_log'] = np.log1p(df['Fare'])

# 히스토그램 시각화
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
sns.histplot(df['Fare'], bins=50, kde=True)
plt.title("Before Log Transformation")

plt.subplot(1, 2, 2)
sns.histplot(df['Fare_log'], bins=50, kde=True)
plt.title("After Log Transformation")

plt.show()
```
✅ **해석:**  
- 로그 변환을 적용하면 데이터의 분포가 **더 정규분포에 가깝게 조정됨**.

---

# **📌 최종 정리**
1️⃣ **이상치 탐색 방법**  
- **IQR (1.5배 기준) → Q1 - 1.5×IQR, Q3 + 1.5×IQR**  
- **Z-score (표준점수) → |Z| > 3**  
- **시각화 (박스플롯, 히스토그램)**  

2️⃣ **이상치 처리 방법**  
- **제거 (Remove)**
- **상한/하한 대체 (Clip)**
- **로그 변환 (Log Transform)**  

---

📢 **이제 이상치를 다루는 방법이 더 명확해졌을 거야!** 🚀  
더 궁금한 게 있으면 질문해줘! 😊
## **🎯 최적의 결측치 처리 전략**
1️⃣ **결측치 비율이 낮다면?** → **제거(drop)**  
2️⃣ **중요한 컬럼이라면?** → **평균(mean), 중앙값(median), 최빈값(mode) 대체**  
3️⃣ **시간순 데이터라면?** → **앞/뒤 값 채우기 (ffill, bfill)**  
4️⃣ **고급 기법을 사용하려면?** → **KNN, 머신러닝 기반 예측 대체**  

👉 **데이터의 특성과 분석 목적에 맞게 적절한 방법을 선택하는 것이 중요합니다!** 😊
