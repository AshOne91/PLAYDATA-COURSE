# 손글씨 분류하기 : 다중 분류
```
데이터 가져오기
데이터 확인 - 몇개의 샘플을 출력, 클래스 수
모델 정의 및 학습 - MLP(다중레이어)
 마지막층 10개
 회귀 : 출력층이 1 손실함수 MSE
 이지분류 : 출력층이 1 손실함수 binary cross entropy
 다중 분류 : 출력층이 클래스 cross entropy
성능평가
추론(예측)
```

다중 분류를 위한 **손글씨 이미지 분류** 문제에서 사용되는 주요 개념들을 항목별로 **자세히 설명**함. 코드 없이 개념 위주로 정리함.

---

### ✅ 데이터 가져오기  
- **데이터셋**: 대표적으로 `MNIST`, `Fashion MNIST`, `CIFAR-10` 등 사용.  
- **형태**: 일반적으로 `(샘플 수, 이미지 높이, 이미지 너비)` 형식의 3차원 배열로 구성됨.  
- **정답(label)**: 각 이미지에 대한 클래스 정수값(0~9)이 포함되어 있음.  

---

### ✅ 데이터 확인  
- **클래스 수 확인**: `np.unique()` 등을 통해 전체 클래스가 몇 개인지 확인 가능.  
- **시각화**: 각 클래스에 해당하는 이미지를 하나씩 뽑아보며 분포 확인 가능.  
- **의미**: 데이터의 다양성, 편향 유무, 클래스별 분포 등을 직관적으로 파악함.  

---

### ✅ 모델 정의 – MLP 구조  
- **MLP (Multi-Layer Perceptron)**: 입력층, 은닉층, 출력층으로 구성된 인공신경망.  
- **Flatten 레이어**: 2차원 이미지 데이터를 1차원 벡터로 변환해 `Dense`층에 전달.  
- **Dense 레이어**: 완전 연결층. 뉴런 수가 많을수록 표현력이 증가함.  
- **ReLU 활성화 함수**: 비선형성을 부여하며 시그모이드 계열의 기울기 소실 문제 해결.  
- **Dropout 레이어**: 과적합 방지를 위해 학습 시 무작위로 일부 뉴런 비활성화.  
- **출력층**:
  - **클래스 수 만큼 노드**를 가짐 (예: 10개 클래스 → 10개 노드).
  - **softmax** 함수 사용: 클래스별 확률을 출력.

---

### ✅ 손실 함수 (Loss Function) 선택 기준  
- **회귀 문제**: 출력층 노드 수 = 1, 손실함수 = MSE, MAE 등  
- **이진 분류**: 출력층 노드 수 = 1, 손실함수 = `binary_crossentropy`, 활성화 함수 = `sigmoid`  
- **다중 분류**: 출력층 노드 수 = 클래스 수, 손실함수 = `categorical_crossentropy` (원-핫),  
  또는 `sparse_categorical_crossentropy` (정수 라벨 사용 시), 활성화 함수 = `softmax`

---

### ✅ 모델 컴파일  
- **optimizer (최적화 알고리즘)**: 대표적으로 `Adam` 사용, 학습률 자동 조절 가능.  
- **loss**: 손실함수. 모델이 얼마나 잘못 예측하는지 계산하는 지표.  
- **metrics**: 성능 평가 지표. 분류 문제의 경우 보통 `accuracy` 사용.

---

### ✅ 모델 학습  
- **에폭 (epoch)**: 전체 학습 데이터를 한 번 다 학습하는 단위.  
- **배치 사이즈**: 데이터를 몇 개씩 묶어서 학습할지 설정.  
- **검증 데이터 (validation_data)**: 모델의 일반화 성능을 확인하기 위해 학습 중 평가하는 데이터셋.  

---

### ✅ 콜백 함수 (Callbacks)  
- **ModelCheckpoint**: 가장 성능 좋은 모델만 저장.  
- **EarlyStopping**: 검증 성능이 일정 기간 향상되지 않으면 학습 조기 종료.  
- **ReduceLROnPlateau**: 검증 성능이 정체될 경우 학습률을 줄여 더 정밀하게 학습.  
- **TensorBoard**: 학습 과정 시각화를 위한 도구. 로그 저장 후 웹 대시보드로 확인 가능.

---

### ✅ 성능 평가  
- **학습 손실 vs 검증 손실 그래프**: 과적합 여부 확인 가능.  
- **정확도 확인**: 학습 정확도와 검증 정확도 비교해 모델 일반화 성능 평가.  
- **테스트셋 평가**: 훈련에 사용되지 않은 데이터에 대한 최종 성능 측정.

---

### ✅ 추론(예측)  
- **예측 결과**: softmax 출력은 클래스별 확률. `argmax`를 통해 가장 높은 확률의 클래스 선택.  
- **시각화**: 예측 결과를 이미지와 함께 비교함으로써 모델 성능 확인 가능.  
- **실제 적용**: 학습된 모델을 실전 데이터에 적용하여 분류 문제 해결에 사용.

---

필요 시 위 내용을 마크다운 문서에 붙여서 `#### 정리` 밑에 삽입하면 됨.

좋음. 지금부터 `reshape`과 `shape`를 확실하게 감 잡을 수 있도록 **1차원부터 4차원까지** 예제 중심으로 구성함.  
각 배열의 `값`, `shape`, 그리고 **실제 구조**를 시각적으로 설명함. 👇

---

## ✅ 1차원 배열

### 🔹 `a = np.array([1, 2, 3, 4, 5, 6])`
```python
print(a.shape)  # (6,)
```
- ✔️ 1차원 배열 (벡터)
- 구조: `[1 2 3 4 5 6]`

---

## ✅ 2차원 배열

### 🔹 `a.reshape(2, 3)`
```python
[[1 2 3]
 [4 5 6]]
```
- ✔️ shape = `(2, 3)` → 2행 3열
- 2차원 행렬

---

## ✅ 3차원 배열

### 🔹 `a.reshape(2, 3, 1)`
```python
[
 [[1], [2], [3]],
 [[4], [5], [6]]
]
```
- ✔️ shape = `(2, 3, 1)`
- 의미:  
  - 2개의 **행렬 묶음**
  - 각 행렬은 3행 1열

---

### 🔹 `a.reshape(1, 2, 3)`
```python
[
 [[1, 2, 3],
  [4, 5, 6]]
]
```
- ✔️ shape = `(1, 2, 3)`
- 의미:  
  - 1개의 묶음  
  - 그 안에 2개의 행 (각 행에 3개 값)

---

## ✅ 4차원 배열

### 🔹 `a.reshape(1, 2, 3, 1)`
```python
[
  [
    [[1], [2], [3]],
    [[4], [5], [6]]
  ]
]
```
- ✔️ shape = `(1, 2, 3, 1)`
- 의미:
  - 1개의 덩어리(batch)
  - 그 안에 2개의 행
  - 각 행은 3개의 값
  - 각 값은 1개 채널

→ 이런 형식은 **이미지 데이터**로 많이 사용됨  
(예: `batch, height, width, channel`)

---

### 🔹 `a.reshape(2, 1, 3, 1)`
```python
[
  [
    [[1], [2], [3]]
  ],
  [
    [[4], [5], [6]]
  ]
]
```
- ✔️ shape = `(2, 1, 3, 1)`
- 의미:  
  - 2개의 묶음  
  - 각 묶음은 1행  
  - 각 행에 3개의 값  
  - 각 값은 1채널

---

## 🔄 차원별 reshape 변화 흐름

```python
a = np.array([1, 2, 3, 4, 5, 6])

a.shape                 # (6,)
a.reshape(2, 3)         # (2, 3)
a.reshape(3, 2)         # (3, 2)
a.reshape(1, 6)         # (1, 6)
a.reshape(6, 1)         # (6, 1)
a.reshape(2, 3, 1)      # (2, 3, 1)
a.reshape(1, 2, 3)      # (1, 2, 3)
a.reshape(1, 2, 3, 1)   # (1, 2, 3, 1)
```

---

## 🔥 실무에서는?

| 차원 | 설명 |
|------|------|
| 1차원 `(6,)` | 일반 벡터 |
| 2차원 `(N, D)` | 데이터셋 (N: 샘플 수, D: 특성 수) |
| 3차원 `(N, T, D)` | 시계열, NLP (예: 문장 길이 T) |
| 4차원 `(N, H, W, C)` | 이미지 데이터 (Height, Width, Channel) |

---

## ❗️ reshape 시 주의점

- **총 원소 개수**는 동일해야 함!
  - 예: `a = np.array([1,2,3,4,5,6])` → 총 6개
  - `reshape(2, 3)` O, `reshape(2, 2)` ❌

---

필요하면 `np.newaxis`, `squeeze()`, `expand_dims()` 같은 것도 다음에 설명 가능.  
계속 연습하면 `shape` 감각 생김. 더 실전 예제 원하면 말해줘.

`reshape(-1, 28*28)` 이 표현은 **딥러닝에서 이미지 데이터를 신경망에 넣기 전에 자주 사용하는 전처리 방식**임.

---

## ✅ 예시: `(60000, 28, 28)` → `reshape(-1, 28*28)`

### 🔹 원래 이미지 데이터
```python
train_data.shape = (60000, 28, 28)
```
- ✔️ 60,000장의 이미지
- 각 이미지 크기: 28 x 28 (흑백 손글씨 이미지)

---

## 🔄 `reshape(-1, 28*28)` 의미

```python
train_data = train_data.reshape(-1, 28*28)
```

➡️ **각 이미지(2차원)를 1차원 벡터(784차원)로 펴줌**

- `28*28 = 784`
- `-1`은 "**자동으로 행 개수 맞춰줘**" 라는 뜻

---

### 🔸 reshape 후의 구조
```python
train_data.shape = (60000, 784)
```

| 샘플 인덱스 | 픽셀1 | 픽셀2 | ... | 픽셀784 |
|-------------|--------|--------|-----|----------|
| 0           | 0.0    | 0.1    | ... | 0.0      |
| 1           | 0.0    | 0.0    | ... | 0.3      |
| ...         | ...    | ...    | ... | ...      |

---

## 📌 왜 이렇게 펴는가?

→ **완전연결층(Dense)** 모델은 입력을 1차원 벡터로 받아야 하기 때문임.

- CNN은 (28, 28, 1) 형식 그대로 처리 가능
- MLP(Dense 모델)는 `(batch_size, input_dim)` 형식이어야 함

---

## 🔍 `-1`의 역할 간단히 정리

| 코드 | 의미 |
|------|------|
| `reshape(-1, 784)` | 784열로 만들고, 행은 데이터 수에 맞춰 자동 계산 |
| `reshape(60000, 784)` | 행과 열 모두 직접 지정 |

둘 다 결과는 같지만, `-1`을 쓰면 **유연한 코드**가 됨.

---

원하는 경우 `(28*28)` 대신 `784` 직접 써도 되지만, 코드 가독성과 실수 방지를 위해 `28*28` 자주 사용됨.  
필요하면 CNN 방식에서 `reshape` 안 하는 경우도 따로 예제로 설명 가능함.

사진 분류 CNN vs VGG
```
CNN 설명
데이터 전처리
  데이터 증강
  이미지 정규화
CNN으로 이미지 분류
  모델정의
  모델학습
  성능평가
VGG(전이학습)
  사전학습된 모델 불러오기
```
좋음. 아래에 너가 제시한 목차에 맞춰 **"사진 분류 CNN vs VGG"** 내용을 마크다운 형식으로 정리함.

---

## 📸 사진 분류 CNN vs VGG

---

### 🔷 CNN 설명

- CNN(Convolutional Neural Network)은 이미지 분류에 특화된 딥러닝 모델.
- 입력 이미지로부터 특징을 추출해 분류하는 구조.
- 일반 구조:
  ```
  Conv → ReLU → Pool → (반복) → Flatten → Dense → Output
  ```
- 주요 계층:
  - **Conv2D**: 이미지의 특징(모서리, 패턴 등)을 추출
  - **ReLU**: 비선형성 부여
  - **MaxPooling**: 크기 축소 및 위치 불변성 확보
  - **Dropout**: 과적합 방지
  - **Dense**: 최종 분류

---

### 🔷 데이터 전처리

#### ✅ 데이터 증강 (Data Augmentation)
- 데이터 양을 증가시키는 기법
- 학습 데이터에 무작위 변형을 가함
- 예: 회전, 이동, 확대, 좌우반전, 노이즈 추가 등
- 과적합 방지 및 일반화 성능 향상

#### ✅ 이미지 정규화
- 픽셀 값(0~255)을 0~1 범위로 정규화
- `이미지 / 255.0` 또는 채널별 평균/표준편차 정규화
- 학습 안정성과 수렴 속도 향상에 도움

---

### 🔷 CNN으로 이미지 분류

#### ✅ 모델 정의
- 입력층: 이미지 크기 (예: 32x32x3)
- Conv2D + ReLU + MaxPooling 반복
- Flatten → Dense → Softmax (출력층)

#### ✅ 모델 학습
- 손실함수: 다중분류 → categorical_crossentropy
- 옵티마이저: Adam, SGD 등
- 지표: 정확도(accuracy)
- Epoch, batch_size 설정

#### ✅ 성능 평가
- 테스트셋에 대해 evaluate()로 정확도 및 손실 측정
- 혼동 행렬(confusion matrix), classification report 사용 가능

---

### 🔷 VGG (전이학습)

#### ✅ 전이학습 개념
- 대규모 데이터셋(ImageNet)으로 학습된 모델을 가져와서 내 문제에 맞게 미세조정
- 적은 데이터로도 높은 성능 가능

#### ✅ 사전학습된 모델 불러오기
- `keras.applications.VGG16`, `VGG19` 등으로 로드
- feature extractor로 사용하거나, 일부 층은 고정(freeze) 후 fine-tuning
- 입력 크기 제한 (보통 224x224), preprocessing 필요

---

필요 시 실제 코드 예제, 학습 결과 시각화, confusion matrix 구현 등도 이어서 설명 가능.


