### **머신러닝 학습을 위한 단계별 필수 용어 정리**  

## **1️⃣ 데이터 전처리 (Preprocessing) 및 탐색적 데이터 분석(EDA)**
- **데이터셋(Dataset)**: 학습에 사용되는 데이터 모음  
- **특성(Feature, 변수, Attribute)**: 입력 데이터의 개별 속성  
- **레이블(Label, 타겟, 종속변수, y값)**: 예측해야 하는 값  
- **정형 데이터(Structured Data)**: 테이블 형태 데이터 (DB, CSV 등)  
- **비정형 데이터(Unstructured Data)**: 이미지, 텍스트, 음성 등  
- **스케일링(Scaling)**: 데이터 크기를 조정하는 과정  
  - **정규화(Normalization)**: 0~1 범위로 조정 (\(X' = \frac{X - X_{min}}{X_{max} - X_{min}}\))  
  - **표준화(Standardization)**: 평균 0, 표준편차 1로 조정 (\(X' = \frac{X - \mu}{\sigma}\))  
- **결측치(Missing Value)**: 데이터 누락값 (삭제, 평균 대체 등 처리 필요)  
- **이상치(Outlier)**: 일반적인 데이터 분포에서 벗어난 값  
- **원-핫 인코딩(One-Hot Encoding)**: 범주형 변수를 이진 벡터로 변환  
- **라벨 인코딩(Label Encoding)**: 범주형 데이터를 숫자로 변환  
- **데이터 분할(Data Split)**: 훈련(Train), 검증(Validation), 테스트(Test) 데이터로 나누는 과정  

---

## **2️⃣ 지도학습(Supervised Learning)**
### **📌 회귀(Regression)**
- **선형 회귀(Linear Regression)**: 직선 형태의 관계를 찾는 회귀 모델  
- **다중 회귀(Multiple Regression)**: 여러 개의 특성을 사용하는 회귀  
- **릿지 회귀(Ridge Regression)**: L2 정규화 사용하여 과적합 방지  
- **라쏘 회귀(Lasso Regression)**: L1 정규화 사용하여 특성 선택  

### **📌 분류(Classification)**
- **로지스틱 회귀(Logistic Regression)**: 이진 분류를 수행하는 모델  
- **서포트 벡터 머신(SVM, Support Vector Machine)**: 데이터 사이의 경계를 찾아 분류  
- **결정 트리(Decision Tree)**: 데이터를 분기하여 분류하는 트리 구조  
- **랜덤 포레스트(Random Forest)**: 여러 개의 결정 트리를 앙상블하여 예측  
- **k-최근접 이웃(KNN, k-Nearest Neighbors)**: 데이터와 가장 가까운 k개의 이웃을 찾아 분류  

---

## **3️⃣ 비지도 학습(Unsupervised Learning)**
- **군집화(Clustering)**: 유사한 데이터를 묶는 방법  
  - **K-평균 군집화(K-Means Clustering)**: 중심점을 기준으로 데이터를 묶는 방법  
  - **DBSCAN**: 밀도가 높은 지역을 기준으로 군집 형성  
  - **계층적 군집화(Hierarchical Clustering)**: 계층 구조로 군집을 구성  
- **차원 축소(Dimensionality Reduction)**: 데이터 특성 개수를 줄이는 방법  
  - **주성분 분석(PCA, Principal Component Analysis)**: 데이터의 분산을 최대한 보존하며 차원 축소  

---

## **4️⃣ 모델 성능 평가 및 튜닝**
- **정확도(Accuracy)**: 전체 데이터 중 정답을 맞춘 비율 (\(\frac{TP + TN}{TP + TN + FP + FN}\))  
- **정밀도(Precision)**: 모델이 긍정 클래스를 예측한 것 중 실제 정답 비율 (\(\frac{TP}{TP+FP}\))  
- **재현율(Recall, Sensitivity)**: 실제 긍정 클래스 중 모델이 올바르게 예측한 비율 (\(\frac{TP}{TP+FN}\))  
- **F1 점수(F1 Score)**: 정밀도와 재현율의 조화 평균 (\(2 \times \frac{Precision \times Recall}{Precision + Recall}\))  
- **ROC 곡선(ROC Curve)**: 이진 분류 모델의 성능을 평가하는 그래프  
- **AUC (Area Under Curve)**: ROC 곡선 아래 면적, 1에 가까울수록 좋음  
- **교차 검증(Cross Validation)**: 데이터를 여러 번 나눠서 모델 성능을 검증하는 방법  
- **과적합(Overfitting)**: 훈련 데이터에만 잘 맞고 새로운 데이터에서 성능이 떨어지는 문제  
- **과소적합(Underfitting)**: 너무 단순한 모델로 인해 성능이 낮은 문제  

---

## **5️⃣ 머신러닝 모델 개선 및 앙상블 기법**
- **배깅(Bagging)**: 데이터를 샘플링하여 여러 모델을 독립적으로 학습 (랜덤 포레스트)  
- **부스팅(Boosting)**: 이전 모델의 오차를 보완하며 점진적으로 학습 (XGBoost, AdaBoost)  
- **스태킹(Stacking)**: 여러 모델의 예측 결과를 메타 모델이 학습하여 최종 예측 수행  
- **투표(Voting)**: 여러 개의 모델을 조합하여 최종 예측을 수행  

---

## **6️⃣ 심층 학습(Deep Learning) 기초**
- **인공 신경망(ANN, Artificial Neural Network)**: 뇌의 뉴런을 모방한 모델  
- **퍼셉트론(Perceptron)**: 가장 기초적인 신경망 모델  
- **다층 퍼셉트론(MLP, Multi-Layer Perceptron)**: 은닉층이 있는 신경망  
- **활성화 함수(Activation Function)**: 뉴런의 출력을 결정하는 함수  
  - **시그모이드(Sigmoid)**: 0~1 값 출력  
  - **ReLU(Rectified Linear Unit)**: 음수는 0, 양수는 그대로 출력  
  - **소프트맥스(Softmax)**: 확률 값으로 변환하여 다중 분류 수행  

---

## **7️⃣ 심층 학습(Deep Learning) 응용**
- **합성곱 신경망(CNN, Convolutional Neural Network)**: 이미지 처리에 특화된 신경망  
- **순환 신경망(RNN, Recurrent Neural Network)**: 시퀀스 데이터(텍스트, 음성 등) 처리  
- **LSTM(Long Short-Term Memory)**: RNN의 장기 의존성 문제 해결  

---

## **8️⃣ 실전 프로젝트 및 응용**
- **추천 시스템(Recommendation System)**: 사용자 선호도 예측 모델  
- **강화 학습(Reinforcement Learning)**: 보상을 기반으로 학습하는 기법  
- **전이 학습(Transfer Learning)**: 사전 학습된 모델을 다른 문제에 적용  
- **AutoML**: 자동으로 최적의 머신러닝 모델을 찾아주는 기술  

---

위 용어들을 익히고 단계별로 학습하면 머신러닝 이해도를 높일 수 있음.
