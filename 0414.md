GAN

진짜와 가짜를 구별수 없을정도로 정교한 가짜를 만드는 생성자를 학습하는 알고리즘
생성자
  가짜 데이터를 만들어냄
  노이즈 데이터(랜덤데이터)를 받아서 진짜같은 이미지나 음성 텍스트등을 생성
판별자(감별자)
  생성자가 만든 가짜와 실제데이터를 비교해서 판단

데이터
  실제데이터
  생성자에 입력할 무작위 노이즈 데이터
가짜 데이터 생성
  생성자는 노이즈 벡터를 받아서 가짜 데이터 생성
판별자 학습
  가짜데이터, 진짜데이터를 모두 입력받아서 각 데이터가 진짜일 확률을 출력    
  보통은 이진분류로 접근 실제데이터는 1, 가짜데이터는 0을 정답레이블로 생성
  손실함수 : 이진크로스엔트로피
생성자 학습
  판별자의 파라메터를 고정한 상태에서 생성자는 업데이트 된다
  판별자가 생성자가 생성한 데이터를 1이라고 잘못 분류하도록 생성자의 파라미터를 조정
  손실함수 : 이진 크로스 엔트로피

  **GAN(Generative Adversarial Network)**  
: 서로 경쟁하며 학습하는 **두 네트워크(생성자 vs 판별자)**를 통해, 진짜처럼 보이는 데이터를 생성하는 알고리즘

---

### 💡 핵심 개념

| 구성요소 | 역할 |
|----------|------|
| **생성자(Generator)** | 랜덤 노이즈 → 진짜처럼 보이는 가짜 데이터 생성 |
| **판별자(Discriminator)** | 입력된 데이터가 진짜인지 가짜인지 판별 |

---

### 🔁 학습 흐름 요약

1. **노이즈 → 생성자 → 가짜 데이터 생성**
2. **진짜 데이터 + 가짜 데이터 → 판별자 입력**
3. **판별자 → 둘 중 뭐가 진짜인지 예측 (이진 분류, BCE Loss 사용)**
4. **판별자 학습**: 진짜는 1, 가짜는 0으로 잘 맞추도록 학습
5. **생성자 학습**: 판별자를 속이기 위해, **가짜를 진짜로 보이게** 만듦 (판별자의 판단이 1이 되도록 생성자 업데이트)
6. 이 과정을 반복하며 생성자는 점점 더 정교한 가짜를 만듦

---

### 🎯 목표  
→ 판별자가 진짜/가짜를 **구분 못할 정도로** 진짜 같은 데이터를 만드는 것!

---

### 📌 손실함수 정리
- 판별자: **BCE Loss** (진짜는 1, 가짜는 0)
- 생성자: **BCE Loss** (가짜를 1로 분류되게 유도)

---

요약:
> **생성자**는 "가짜를 진짜처럼 만들고",  
> **판별자**는 "진짜와 가짜를 구분"하며,  
> **둘이 경쟁하며 같이 발전하는 구조**

필요하면 코드 예제도 바로 줄게요!

맞습니다. GAN의 **감별자(Discriminator)**는 기본적으로 **CNN(합성곱 신경망)**과 매우 유사한 구조를 가집니다. 아래에 정리해드릴게요.

---

### 🧠 감별자(Discriminator)란?

> 생성자가 만든 **가짜 데이터**와 **진짜 데이터**를 구별하는 **이진 분류기(Binary Classifier)** 역할.

---

### 🔧 구성 방식

- **입력**: 이미지 또는 생성자가 만든 가짜 이미지
- **합성곱 레이어(Conv2D)**: 이미지 특징 추출
- **배치 정규화(BatchNorm)**: 학습 안정화, 수렴 속도 향상
- **활성화 함수**: LeakyReLU 자주 사용 (ReLU는 죽은 뉴런 발생 위험)
- **풀링 없이 stride로 다운샘플링**
- **출력층**: sigmoid (결과값: 0=가짜, 1=진짜)

---

### 📌 예시 구조
```plaintext
Input (이미지)
↓
Conv2D (stride=2) + LeakyReLU + BatchNorm
↓
Conv2D (stride=2) + LeakyReLU + BatchNorm
↓
Flatten
↓
Dense (1) + Sigmoid
```

---

### ✅ 정리

- **기존 CNN처럼 구성됨**
- 핵심은 **진짜 vs 가짜**를 구분하는 **이진 분류 문제**
- 생성자의 학습을 유도하기 위해 **정확하게 구분하는 능력**이 중요함

---

가중치 초기화
GAN  
  합성곱(평균0.0 표준편차0.02), --> DCGAN  2015 논문에서 제안된 값
  배치정규화(1.0, 0.02)는 가중치 초기화   1.0은 출력분포가 원래대로 유지
  배치 정규화층의 편향은 0으로 설정  -> 미세조정 및 출력평균을 조절, 보통 0으로 시작하는게 일반적인 상황
  평균이 0 이고 표준편차가 0.02 --> 학습이 가장 잘 되는 case --> 경험적으로 발견한 값

깔끔하게 요약해드릴게요.  
GAN (특히 DCGAN)에서 **가중치 초기화**는 학습 안정성과 품질에 아주 중요한 역할을 합니다.

---

### 🎯 GAN 가중치 초기화 요약

#### ✅ 합성곱(Conv) 레이어
- **평균 0.0**, **표준편차 0.02**로 정규분포에서 초기화  
- DCGAN 논문(2015)에서 제안  
- 이유: 너무 크거나 작은 값은 **기울기 폭발/소실** 문제 유발

```python
# PyTorch 예시
def weights_init(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
        nn.init.normal_(m.weight.data, 0.0, 0.02)
```

---

#### ✅ 배치 정규화(BatchNorm) 레이어
- **가중치(γ)**: 평균 **1.0**, 표준편차 **0.02**  
- **편향(β)**: **0.0**으로 설정  
- 이유:
  - γ = 1.0: 정규화된 값을 그대로 유지
  - β = 0.0: 출력 평균을 0에서 시작하도록 조정

```python
# PyTorch 예시
elif isinstance(m, nn.BatchNorm2d):
    nn.init.normal_(m.weight.data, 1.0, 0.02)
    nn.init.constant_(m.bias.data, 0)
```

---

### 🔍 왜 이렇게?
- **경험적으로** 가장 잘 학습됨 (DCGAN에서 테스트함)
- 너무 큰 값 → 불안정
- 너무 작은 값 → 수렴 느림 or 학습 안 됨

---

요약하면:
> GAN 초기화 = `Conv: N(0, 0.02)` / `BatchNorm: γ=1.0±0.02, β=0`

추가로 Xavier, He 초기화도 있지만, GAN에서는 이 방식이 더 잘 먹힘으로 알려져 있어요.

필요하면 텐서플로/케라스 코드도 드릴게요.

좋아, 정말 쉽게! 지금부터 너가 작성한 GAN 전체 코드 한 줄 한 줄, 차근차근 설명해줄게.  
GAN(생성적 적대 신경망)을 직접 만들었고, 특히 얼굴 이미지를 생성하는 CelebA 데이터셋 기반 DCGAN 구조야.

---

## 🔽 먼저 순서대로 나눠서 설명할게:

---

## ① **CelebA 이미지 준비**

```python
from glob import glob
from PIL import Image

file_lists = glob('/content/GAN/img_align_celeba/*.jpg')  # 폴더 안에 있는 모든 jpg 파일을 리스트로 가져옴
Image.open(file_lists[1100])  # 그 중 하나를 열어서 보여줌
```

📌 **설명:**
- `glob()` 함수는 이미지 파일 경로들을 모아 리스트로 줘.
- `Image.open()`은 PIL 라이브러리로 이미지를 불러오는 함수.
- → 즉, 얼굴 이미지를 제대로 불러오는지 확인한 거야.

---

## ② **이미지 전처리 + 데이터로더 만들기**

```python
transforms = tf.Compose([
    tf.Resize((64,64)),  # 모든 이미지를 64x64로 리사이즈
    tf.CenterCrop(64),  # 중앙에서 잘라서 다시 64x64
    tf.ToTensor(),  # 이미지를 0~1 범위의 텐서로 변환
    tf.Normalize(mean=(0.5,0.5,0.5), std=(0.25,0.25,0.25))  # 정규화 (-1 ~ 1 정도로 바뀜)
])
```

📌 **설명:**
- 모든 이미지를 같은 크기와 값 범위로 맞추는 작업 (신경망이 학습하기 쉽게)

```python
dataset = ImageFolder(root='./GAN',transform=transforms)
loader = DataLoader(dataset, batch_size=128,shuffle=True)
```

📌 **설명:**
- `ImageFolder`는 폴더 구조에서 이미지 데이터셋을 만드는 클래스야.
- `DataLoader`는 한 번에 128장의 이미지 배치로 만들어서 섞어줌.

---

## ③ **Generator (생성자) 만들기**

```python
class Generator(nn.Module):
  def __init__(self):
    super().__init__()
    self.gen = nn.Sequential(
        nn.ConvTranspose2d(100,512,kernel_size=4,bias=False),  # 1x1 → 4x4
        nn.BatchNorm2d(512),
        nn.ReLU(),

        nn.ConvTranspose2d(512,256,kernel_size=4,stride=2,padding=1,bias=False),  # 4x4 → 8x8
        nn.BatchNorm2d(256),
        nn.ReLU(),

        nn.ConvTranspose2d(256,128,kernel_size=4,stride=2,padding=1,bias=False),  # 8x8 → 16x16
        nn.BatchNorm2d(128),
        nn.ReLU(),

        nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1,bias=False),  # 16x16 → 32x32
        nn.BatchNorm2d(64),
        nn.ReLU(),

        nn.ConvTranspose2d(64,3,kernel_size=4,stride=2,padding=1,bias=False),  # 32x32 → 64x64
        nn.Tanh()  # 출력 값 -1 ~ 1 범위로 (이미지가 그렇게 정규화되어 있었으니까)
    )
```

📌 **설명:**
- `ConvTranspose2d`는 이미지 크기를 늘리는 업샘플링 연산 (노이즈 → 이미지로 바뀜)
- `BatchNorm2d`는 학습 안정화를 도와줌
- `ReLU`는 비선형성 (활성화 함수)
- `Tanh()`는 마지막 출력 값을 -1~1 사이로 바꿈 (데이터가 그렇게 정규화됐으니까)

---

## ④ **Generator 출력 테스트**

```python
z = torch.randn(1,100,1,1)  # 랜덤 노이즈 (정규분포에서 샘플)
g = Generator()
temp_img = g(z)[0].permute(1,2,0).detach().numpy()
temp_img = (temp_img + 1) / 2  # Tanh로 -1~1 → 0~1 복구
plt.imshow(temp_img)
```

📌 **설명:**
- `z`는 생성자의 입력
- `permute(1,2,0)`는 채널 순서를 이미지용으로 바꿔줌
- `detach()`는 계산 그래프에서 빼줘 (시각화 용도)
- `(temp_img + 1)/2`는 원래 이미지처럼 보이게 역정규화

---

## ⑤ **Discriminator (감별자) 만들기**

```python
class Discriminator(nn.Module):
  def __init__(self):
    super().__init__()
    self.disc = nn.Sequential(
        nn.Conv2d(3,64,kernel_size=4,stride=2,padding=1,bias=False),
        nn.BatchNorm2d(64),
        nn.LeakyReLU(0.2),

        nn.Conv2d(64,128,kernel_size=4,stride=2,padding=1,bias=False),
        nn.BatchNorm2d(128),
        nn.LeakyReLU(0.2),

        nn.Conv2d(128,256,kernel_size=4,stride=2,padding=1,bias=False),
        nn.BatchNorm2d(256),
        nn.LeakyReLU(0.2),

        nn.Conv2d(256,512,kernel_size=4,stride=2,padding=1,bias=False),
        nn.BatchNorm2d(512),
        nn.LeakyReLU(0.2),

        nn.Conv2d(512,1,kernel_size=4),  # 마지막 출력 (진짜 or 가짜 판별)
    )
```

📌 **설명:**
- `Conv2d`: 이미지의 특징을 추출하면서 해상도 줄임
- `LeakyReLU`: 음수 입력도 약간 살려줌 (죽은 뉴런 방지)
- 마지막 Conv → 1개 값 출력 → 진짜인지 가짜인지 판단

---

## ⑥ **가중치 초기화 함수**

```python
def weights_init(m):
  classname = m.__class__.__name__
  if classname.find('Conv') != -1:
    nn.init.normal_(m.weight.data, mean=0.0, std=0.02)
  elif classname.find('Batch') != -1:
    nn.init.normal_(m.weight.data, mean=1.0, std=0.02)
    nn.init.constant_(m.bias.data, 0)
```

📌 **설명:**
- DCGAN 논문에서 제안한 초기화 방식 (학습 잘 되게 도와줌)
- Conv는 평균 0, 표준편차 0.02로 초기화
- 배치 정규화는 평균 1, 편차 0.02로 초기화. bias는 0

---

## ⑦ **모델/옵티마이저/손실함수 정의**

```python
G = Generator().to(device)
G.apply(weights_init)

D = Discriminator().to(device)
D.apply(weights_init)

G_optim = torch.optim.Adam(G.parameters(), lr=1e-4)
D_optim = torch.optim.Adam(D.parameters(), lr=1e-4)

Dloss_fn = nn.BCEWithLogitsLoss()  # 판별자용
Gloss_fn = nn.BCEWithLogitsLoss()  # 생성자용
```

📌 **설명:**
- 생성자, 감별자 정의 + GPU 올림
- 가중치 초기화 적용
- 옵티마이저는 Adam 사용
- 손실함수는 BCEWithLogitsLoss (시그모이드 포함된 이진분류용)

---

## ⑧ **학습 루프**

너무 길어서 다음 답변에서 학습 루프(핵심 부분!)부터 이어서 설명할게! 준비됐지? 😎  
계속 알려줄게 → `for epoch in range(50):` 부터!

좋아! 이제 제일 중요한 **학습 루프 부분**을 줄줄이 해석해줄게. 완전 쉽게!

---

## 🔁 학습 루프 시작

```python
for epoch in range(50):
  iterator = tqdm(loader)
```

📌 **설명:**
- 총 50번 반복해서 학습할 거야 (즉, 에폭 50번)
- `tqdm`은 로딩 바를 만들어서 진행 상황 보여줌

---

## 🧠 감별자 학습 - 진짜 이미지 학습

```python
for data in iterator:
    D_optim.zero_grad()
```

📌 옵티마이저 초기화 (기존 기울기 지움)

```python
    label = torch.ones_like(data[1], dtype=torch.float32).to(device)
    label_fake = torch.zeros_like(data[1], dtype=torch.float32).to(device)
```

📌 진짜 이미지의 정답은 `1`, 가짜 이미지는 `0`으로 정해줌  
※ 이때 `data[1]`은 라벨 (우린 이미지 분류 안 쓰지만 모양 맞추려고 씀)

```python
    real = D(data[0].to(device))  # 진짜 이미지 넣고
    Dloss_real = Dloss_fn(torch.squeeze(real), label)
    Dloss_real.backward()
```

📌 진짜 이미지 넣고 감별자 결과값 얻어서  
`1에 가까워야 하니까 → label=1`  
→ 그 오차로 역전파해서 감별자 업데이트 준비!

---

## 🤖 감별자 학습 - 가짜 이미지 학습

```python
    noise = torch.randn(label.shape[0], 100, 1, 1, device=device)
    fake = G(noise)  # 생성자에 노이즈 넣어 가짜 이미지 생성
```

```python
    output = D(fake.detach())  # 가짜 이미지 넣음
    Dloss_fake = Dloss_fn(torch.squeeze(output), label_fake)
    Dloss_fake.backward()
```

📌 감별자는 `가짜 이미지 → 0`이라고 말해야 해  
→ 그래서 `label_fake = 0`  
→ 그 오차로 다시 역전파

```python
    Dloss = Dloss_real + Dloss_fake
    D_optim.step()
```

📌 진짜 이미지에서의 손실 + 가짜 이미지에서의 손실  
→ 합쳐서 감별자 업데이트 완료! 🎉

---

## 🧑‍🎨 생성자 학습

```python
    G_optim.zero_grad()
    output = D(fake)  # 다시 생성된 가짜 이미지 감별자에 넣음
    Gloss = Gloss_fn(torch.squeeze(output), label)  # 여기서 label은 1!
    Gloss.backward()
    G_optim.step()
```

📌 생성자의 목표:
> 가짜 이미지를 넣었을 때 감별자가 **진짜라고 속도록** 만들어야 해

그래서 정답을 `1`로 설정해서 역전파  
→ 감별자를 속이는 방향으로 학습됨!

---

## 🖥️ 로깅

```python
    iterator.set_description(f"epoch : {epoch+1}")
    iterator.set_postfix(d_loss=Dloss.item(), g_loss=Gloss.item())
```

📌 지금 에폭 번호와 감별자/생성자의 손실값을 계속 출력  
→ 잘 학습되고 있는지 확인용!

---

## 💾 결과 저장은 아래 주석처럼
```python
# 필요시 세이브
```

📌 `torch.save(G.state_dict())` 이런 걸로 저장할 수 있어 (필요하면 알려줘!)

---

## 🧠 전체 정리 한 줄 요약:

- 감별자(D)는 진짜/가짜를 맞히려고 훈련
- 생성자(G)는 감별자를 속이려고 훈련
- 두 모델이 서로 경쟁하며 점점 진짜 같은 이미지를 만들게 됨!

---

필요하면 그림으로도 GAN 구조 정리해줄 수 있어!  
그리고 이 코드로 나온 이미지들을 어떻게 저장하거나 시각화하는지도 알려줄게.

궁금한 거 이어서 물어봐 😎  
예: "진짜/가짜 구분은 어떻게 되는 거야?" 같은 것도 OK!

강화학습
에이전트가 환경과 심화작용하며 보상을 최대화 하는 정책을 학습
환경 : 학습이 이루어지는 공간(게임, 시뮬레이션)
에이전트 : 환경에서 행동을 선택하는 주제
행동 : 에이전트가 환경에 맞게 취할수 있는 행동(왼쪽/오른쪽)
보상 : 행동에 따라서 환경이 제공하는 평가값(목표달성시 양의값)
