# **PCA(주성분 분석) 및 인공신경망 개요 + 예제**

---

## **1. PCA (Principal Component Analysis, 주성분 분석)**

### 📌 **PCA란?**
- 다차원 데이터를 **차원 축소**하여 주요 패턴을 추출하는 **통계 기법**  
- 데이터의 **분산(Variance)**을 최대화하는 방향으로 새로운 좌표계를 설정함  
- 설정된 좌표계를 **주성분(Principal Component)**이라 하며, 정보 손실을 최소화하면서 차원을 축소하는 것이 목적  

### **PCA 절차 + 예제**
1️⃣ **데이터 표준화**  
   - 특성 간의 스케일 차이를 없애기 위해 **평균을 0, 표준편차를 1**로 변환  
   - 📌 **예제 (Python 코드)**  
     ```python
     from sklearn.preprocessing import StandardScaler
     import numpy as np

     # 예제 데이터 (학생 수학, 과학 성적)
     data = np.array([[85, 90], [88, 85], [75, 80], [95, 95], [80, 75]])

     # 표준화
     scaler = StandardScaler()
     data_std = scaler.fit_transform(data)
     print(data_std)
     ```

2️⃣ **공분산 행렬 계산**  
   - 변수들 간의 관계(상관성, 분산)를 나타내는 **공분산 행렬** 계산  
   - 📌 **예제**
     ```python
     cov_matrix = np.cov(data_std.T)
     print(cov_matrix)
     ```

3️⃣ **고유값(Eigenvalue)과 고유벡터(Eigenvector) 계산**  
   - 공분산 행렬을 **고유값 분해**하여 주성분의 방향과 크기 결정  
   - 📌 **예제**
     ```python
     from numpy.linalg import eig
     eigenvalues, eigenvectors = eig(cov_matrix)
     print("고유값:", eigenvalues)
     print("고유벡터:", eigenvectors)
     ```

4️⃣ **주성분 선택**  
   - 고유값이 큰 순서대로 주성분을 선택  
   - 보통 **전체 분산의 80~90% 이상**을 설명하는 주성분 개수를 선택  

5️⃣ **데이터 변환**  
   - **고유벡터 행렬**을 사용해 원래 데이터를 새로운 좌표계(주성분 공간)로 변환  
   - 📌 **예제**
     ```python
     pca_data = np.dot(data_std, eigenvectors)
     print("PCA 변환 데이터:", pca_data)
     ```

---

### **📊 PCA를 실제 데이터에 적용해보기**
```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris

# 데이터 불러오기
iris = load_iris()
X = iris.data  # 특성 데이터

# PCA 적용 (2차원으로 축소)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# 시각화
plt.figure(figsize=(8,6))
sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=iris.target, palette="Set1")
plt.xlabel("주성분 1")
plt.ylabel("주성분 2")
plt.title("Iris 데이터 PCA 변환")
plt.show()
```
✅ **결과**: 4차원 데이터를 2차원으로 축소하여 시각화 가능

---

## **2. 인공신경망(Artificial Neural Network, ANN)**

### 📌 **신경망이란?**
- **생물학적 신경망(Neuron)의 구조**를 본떠 만든 모델  
- **입력층(Input Layer), 은닉층(Hidden Layer), 출력층(Output Layer)**으로 구성됨  
- **활성화 함수(Activation Function)**를 사용하여 일정 임계치를 넘으면 다음 층으로 신호 전달  

---

### **1️⃣ 로지스틱 회귀(Logistic Regression)**
- **이진 분류(Binary Classification)** 모델  
- 📌 **예제 (MNIST 숫자 이미지 분류 - 로지스틱 회귀)**
  ```python
  from sklearn.linear_model import LogisticRegression
  from sklearn.datasets import load_digits
  from sklearn.model_selection import train_test_split
  from sklearn.metrics import accuracy_score

  # 데이터 로드
  digits = load_digits()
  X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)

  # 모델 학습
  model = LogisticRegression(max_iter=10000)
  model.fit(X_train, y_train)

  # 예측 및 정확도 평가
  y_pred = model.predict(X_test)
  print("로지스틱 회귀 정확도:", accuracy_score(y_test, y_pred))
  ```
✅ **결과**: 숫자 인식 성능 확인 가능  

---

### **2️⃣ 인공신경망(ANN) 모델 구현**
- 📌 **예제 (Fashion MNIST 데이터 - 신경망 적용)**
  ```python
  import tensorflow as tf
  from tensorflow.keras import layers, models
  from tensorflow.keras.datasets import fashion_mnist
  import matplotlib.pyplot as plt

  # 데이터 로드 및 전처리
  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
  X_train, X_test = X_train / 255.0, X_test / 255.0  # 정규화

  # 신경망 모델 정의
  model = models.Sequential([
      layers.Flatten(input_shape=(28, 28)),  # 2D 이미지를 1D로 변환
      layers.Dense(128, activation='relu'),  # 은닉층
      layers.Dense(10, activation='softmax') # 출력층 (10개 클래스)
  ])

  # 모델 컴파일
  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

  # 모델 학습
  model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

  # 모델 평가
  test_loss, test_acc = model.evaluate(X_test, y_test)
  print("신경망 테스트 정확도:", test_acc)
  ```
✅ **결과**: 패션 MNIST 분류 성능 확인 가능  

---

## **3. PCA와 신경망 결합하기**
1️⃣ PCA를 사용하여 차원 축소  
2️⃣ 축소된 데이터를 신경망(ANN)에 입력  
3️⃣ 연산량을 줄이고 모델 성능을 비교  

📌 **PCA + ANN 예제**
```python
# PCA 적용
pca = PCA(n_components=50)  # 784차원 → 50차원 축소
X_train_pca = pca.fit_transform(X_train.reshape(-1, 28*28))
X_test_pca = pca.transform(X_test.reshape(-1, 28*28))

# 신경망 모델 정의
model = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(50,)),  # 입력 차원 변경
    layers.Dense(10, activation='softmax')
])

# 모델 학습
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train_pca, y_train, epochs=10, validation_data=(X_test_pca, y_test))
```
✅ **결과**: PCA로 축소 후 ANN 적용하여 성능 평가 가능  

---

## **4. 요약**
✅ **PCA(주성분 분석)**:  
- 데이터의 차원을 축소하여 주요 정보를 보존하는 기법  
- **설명된 분산 비율**을 통해 주성분 개수 결정  
- **분류기와 함께 사용 가능하나 성능이 낮아질 수도 있음**  

✅ **인공신경망(ANN)**:  
- 다층 퍼셉트론(MLP) 구조를 사용하여 비선형 문제 해결  
- 딥러닝(Deep Learning)의 기초  

✅ **PCA + 신경망 조합 가능**  
- **PCA로 차원을 줄이고 ANN을 적용하여 성능 비교 가능**  
- 계산량을 줄일 수 있지만 성능이 떨어질 수도 있음  

이제 PCA와 신경망을 실제 데이터에 활용해서 실험해보면 좋을 것임! 🚀


