# **PCA(주성분 분석) 및 인공신경망 개요 + 예제**

---

## **1. PCA (Principal Component Analysis, 주성분 분석)**

### 📌 **PCA란?**
- 다차원 데이터를 **차원 축소**하여 주요 패턴을 추출하는 **통계 기법**  
- 데이터의 **분산(Variance)**을 최대화하는 방향으로 새로운 좌표계를 설정함  
- 설정된 좌표계를 **주성분(Principal Component)**이라 하며, 정보 손실을 최소화하면서 차원을 축소하는 것이 목적  

### **PCA 절차 + 예제**
1️⃣ **데이터 표준화**  
   - 특성 간의 스케일 차이를 없애기 위해 **평균을 0, 표준편차를 1**로 변환  
   - 📌 **예제 (Python 코드)**  
     ```python
     from sklearn.preprocessing import StandardScaler
     import numpy as np

     # 예제 데이터 (학생 수학, 과학 성적)
     data = np.array([[85, 90], [88, 85], [75, 80], [95, 95], [80, 75]])

     # 표준화
     scaler = StandardScaler()
     data_std = scaler.fit_transform(data)
     print(data_std)
     ```

2️⃣ **공분산 행렬 계산**  
   - 변수들 간의 관계(상관성, 분산)를 나타내는 **공분산 행렬** 계산  
   - 📌 **예제**
     ```python
     cov_matrix = np.cov(data_std.T)
     print(cov_matrix)
     ```

3️⃣ **고유값(Eigenvalue)과 고유벡터(Eigenvector) 계산**  
   - 공분산 행렬을 **고유값 분해**하여 주성분의 방향과 크기 결정  
   - 📌 **예제**
     ```python
     from numpy.linalg import eig
     eigenvalues, eigenvectors = eig(cov_matrix)
     print("고유값:", eigenvalues)
     print("고유벡터:", eigenvectors)
     ```

4️⃣ **주성분 선택**  
   - 고유값이 큰 순서대로 주성분을 선택  
   - 보통 **전체 분산의 80~90% 이상**을 설명하는 주성분 개수를 선택  

5️⃣ **데이터 변환**  
   - **고유벡터 행렬**을 사용해 원래 데이터를 새로운 좌표계(주성분 공간)로 변환  
   - 📌 **예제**
     ```python
     pca_data = np.dot(data_std, eigenvectors)
     print("PCA 변환 데이터:", pca_data)
     ```

---

### **📊 PCA를 실제 데이터에 적용해보기**
```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris

# 데이터 불러오기
iris = load_iris()
X = iris.data  # 특성 데이터

# PCA 적용 (2차원으로 축소)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# 시각화
plt.figure(figsize=(8,6))
sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=iris.target, palette="Set1")
plt.xlabel("주성분 1")
plt.ylabel("주성분 2")
plt.title("Iris 데이터 PCA 변환")
plt.show()
```
✅ **결과**: 4차원 데이터를 2차원으로 축소하여 시각화 가능

---

## **2. 인공신경망(Artificial Neural Network, ANN)**

### 📌 **신경망이란?**
- **생물학적 신경망(Neuron)의 구조**를 본떠 만든 모델  
- **입력층(Input Layer), 은닉층(Hidden Layer), 출력층(Output Layer)**으로 구성됨  
- **활성화 함수(Activation Function)**를 사용하여 일정 임계치를 넘으면 다음 층으로 신호 전달  

---

### **1️⃣ 로지스틱 회귀(Logistic Regression)**
- **이진 분류(Binary Classification)** 모델  
- 📌 **예제 (MNIST 숫자 이미지 분류 - 로지스틱 회귀)**
  ```python
  from sklearn.linear_model import LogisticRegression
  from sklearn.datasets import load_digits
  from sklearn.model_selection import train_test_split
  from sklearn.metrics import accuracy_score

  # 데이터 로드
  digits = load_digits()
  X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)

  # 모델 학습
  model = LogisticRegression(max_iter=10000)
  model.fit(X_train, y_train)

  # 예측 및 정확도 평가
  y_pred = model.predict(X_test)
  print("로지스틱 회귀 정확도:", accuracy_score(y_test, y_pred))
  ```
✅ **결과**: 숫자 인식 성능 확인 가능  

---

### **2️⃣ 인공신경망(ANN) 모델 구현**
- 📌 **예제 (Fashion MNIST 데이터 - 신경망 적용)**
  ```python
  import tensorflow as tf
  from tensorflow.keras import layers, models
  from tensorflow.keras.datasets import fashion_mnist
  import matplotlib.pyplot as plt

  # 데이터 로드 및 전처리
  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
  X_train, X_test = X_train / 255.0, X_test / 255.0  # 정규화

  # 신경망 모델 정의
  model = models.Sequential([
      layers.Flatten(input_shape=(28, 28)),  # 2D 이미지를 1D로 변환
      layers.Dense(128, activation='relu'),  # 은닉층
      layers.Dense(10, activation='softmax') # 출력층 (10개 클래스)
  ])

  # 모델 컴파일
  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

  # 모델 학습
  model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

  # 모델 평가
  test_loss, test_acc = model.evaluate(X_test, y_test)
  print("신경망 테스트 정확도:", test_acc)
  ```
✅ **결과**: 패션 MNIST 분류 성능 확인 가능  

---

## **3. PCA와 신경망 결합하기**
1️⃣ PCA를 사용하여 차원 축소  
2️⃣ 축소된 데이터를 신경망(ANN)에 입력  
3️⃣ 연산량을 줄이고 모델 성능을 비교  

📌 **PCA + ANN 예제**
```python
# PCA 적용
pca = PCA(n_components=50)  # 784차원 → 50차원 축소
X_train_pca = pca.fit_transform(X_train.reshape(-1, 28*28))
X_test_pca = pca.transform(X_test.reshape(-1, 28*28))

# 신경망 모델 정의
model = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(50,)),  # 입력 차원 변경
    layers.Dense(10, activation='softmax')
])

# 모델 학습
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train_pca, y_train, epochs=10, validation_data=(X_test_pca, y_test))
```
✅ **결과**: PCA로 축소 후 ANN 적용하여 성능 평가 가능  

---

## **4. 요약**
✅ **PCA(주성분 분석)**:  
- 데이터의 차원을 축소하여 주요 정보를 보존하는 기법  
- **설명된 분산 비율**을 통해 주성분 개수 결정  
- **분류기와 함께 사용 가능하나 성능이 낮아질 수도 있음**  

✅ **인공신경망(ANN)**:  
- 다층 퍼셉트론(MLP) 구조를 사용하여 비선형 문제 해결  
- 딥러닝(Deep Learning)의 기초  

✅ **PCA + 신경망 조합 가능**  
- **PCA로 차원을 줄이고 ANN을 적용하여 성능 비교 가능**  
- 계산량을 줄일 수 있지만 성능이 떨어질 수도 있음  

이제 PCA와 신경망을 실제 데이터에 활용해서 실험해보면 좋을 것임! 🚀

## **📌 머신러닝 분류 모델에 적용 - 랜덤포레스트 (RandomForestClassifier)**

### **1️⃣ 랜덤포레스트 개요**
- 랜덤포레스트(RandomForest)는 여러 개의 **의사결정나무(Decision Tree)**를 조합하여 예측을 수행하는 **앙상블 학습(Ensemble Learning)** 방법임.
- 개별 트리가 과적합되는 것을 방지하고 **더 높은 예측 정확도를 제공**하는 장점이 있음.
- 특히 **범주형 데이터 처리에 강함** → 수치형 데이터를 범주형으로 변환하면 성능이 향상될 수 있음.

---

### **2️⃣ 랜덤포레스트 적용 과정**
#### **① 데이터 준비**
👉 `UCI Adult Income Dataset` 사용 (수입이 50K 이상인지 예측)

```python
# 필요한 라이브러리 불러오기
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# UCI 데이터 로드
from ucimlrepo import fetch_ucirepo
adult = fetch_ucirepo(id=2)

# 특성과 타겟 분리
X = adult.data.features
y = adult.data.targets
```

---

#### **② 데이터 전처리**
✅ **수치형 데이터 표준화(Standardization)**
✅ **범주형 데이터 인코딩(Label Encoding)**

```python
# 범주형 데이터 라벨 인코딩
label_encoders = {}
for col in X.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    label_encoders[col] = le

# 데이터 분할 (80% 학습, 20% 테스트)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

---

#### **③ 랜덤포레스트 모델 학습**
```python
# 랜덤포레스트 모델 학습
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 예측 및 정확도 평가
y_pred = rf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"랜덤포레스트 정확도: {accuracy:.4f}")
```

✅ **결과:**  
랜덤포레스트 모델이 수입을 예측하는 정확도를 계산할 수 있음.

---

### **3️⃣ 파이프라인(Pipeline) 자동화**
- 전처리 + 모델 학습 + 예측을 하나의 흐름으로 자동화  
- **장점:** 여러 단계의 처리를 한 번에 실행 가능

```python
# 랜덤포레스트 파이프라인 구축
pipeline = Pipeline([
    ('scaler', StandardScaler()),       # 스케일링
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # 모델
])

# 파이프라인 학습
pipeline.fit(X_train, y_train)

# 파이프라인 예측
y_pred_pipeline = pipeline.predict(X_test)
accuracy_pipeline = accuracy_score(y_test, y_pred_pipeline)

print(f"파이프라인 적용 후 정확도: {accuracy_pipeline:.4f}")
```

✅ **결과:**  
- **파이프라인을 사용하면 데이터 전처리부터 모델 학습까지 자동으로 진행됨.**
- **코드 유지보수 및 확장성이 증가함.**

---

## **📌 인공신경망 (Artificial Neural Network, ANN)**
### **1️⃣ 개요**
- 인간의 **뉴런(Neuron) 구조**를 모방하여 설계된 신경망 모델
- 입력층(Input Layer) → 은닉층(Hidden Layer) → 출력층(Output Layer) 구조
- **활성화 함수(Activation Function)**를 사용하여 입력을 비선형 변환하여 학습
- **이미지, 텍스트, 음성 데이터 분석 등에 사용됨**

---

### **2️⃣ ANN 적용 예제 (Fashion MNIST 데이터셋)**
✅ **Fashion MNIST 데이터셋**:  
- 28x28 픽셀의 흑백 이미지로 이루어진 **10개 의류 카테고리 분류**
- 신경망을 사용해 옷의 종류를 분류하는 문제

#### **① 데이터 로드 및 전처리**
```python
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# 데이터 로드
fashion_mnist = tf.keras.datasets.fashion_mnist
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

# 데이터 정규화 (0~255 → 0~1)
X_train, X_test = X_train / 255.0, X_test / 255.0
```

---

#### **② 신경망 모델 설계**
✅ **Dense 레이어**를 쌓아 Fully Connected 신경망 생성  
✅ **ReLU 활성화 함수** 사용  
✅ **Softmax 함수**로 10개 클래스 분류  

```python
# 신경망 모델 정의
model = models.Sequential([
    layers.Flatten(input_shape=(28, 28)),       # 2D → 1D 변환
    layers.Dense(128, activation='relu'),       # 은닉층 1 (128개 뉴런, ReLU)
    layers.Dense(64, activation='relu'),        # 은닉층 2 (64개 뉴런, ReLU)
    layers.Dense(10, activation='softmax')      # 출력층 (10개 클래스, Softmax)
])

# 모델 컴파일
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 모델 요약 출력
model.summary()
```

---

#### **③ 모델 학습 및 평가**
```python
# 모델 학습
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# 모델 평가
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
print(f"테스트 정확도: {test_acc:.4f}")
```

✅ **결과:**  
Fashion MNIST 데이터셋을 학습한 후, **의류를 10개 카테고리로 분류하는 신경망 모델**을 구축할 수 있음.

---

## **📌 결론**
| 모델 | 특징 | 예제 |
|------|------|------|
| **랜덤포레스트** | 다수의 의사결정나무를 조합해 성능 향상 | 성인 소득 예측 (50K 이상 여부) |
| **파이프라인** | 데이터 전처리 + 모델 학습을 자동화 | `Pipeline`을 사용한 학습 |
| **인공신경망** | 뉴런 구조를 모방, 딥러닝의 기본 구조 | Fashion MNIST 의류 분류 |

🚀 **정리:**  
- 랜덤포레스트는 **분류 문제에서 성능이 뛰어나며, 파이프라인을 사용하면 자동화 가능**  
- 인공신경망(ANN)은 **비선형 데이터를 처리할 수 있으며, 이미지 및 복잡한 데이터 분석에 적합**  
- 각 방법을 **데이터 특성에 맞게 선택하여 적용해야 함.**


