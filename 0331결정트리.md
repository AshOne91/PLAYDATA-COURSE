# **PCA(ì£¼ì„±ë¶„ ë¶„ì„) ë° ì¸ê³µì‹ ê²½ë§ ê°œìš” + ì˜ˆì œ**

---

## **1. PCA (Principal Component Analysis, ì£¼ì„±ë¶„ ë¶„ì„)**

### ğŸ“Œ **PCAë€?**
- ë‹¤ì°¨ì› ë°ì´í„°ë¥¼ **ì°¨ì› ì¶•ì†Œ**í•˜ì—¬ ì£¼ìš” íŒ¨í„´ì„ ì¶”ì¶œí•˜ëŠ” **í†µê³„ ê¸°ë²•**  
- ë°ì´í„°ì˜ **ë¶„ì‚°(Variance)**ì„ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ìƒˆë¡œìš´ ì¢Œí‘œê³„ë¥¼ ì„¤ì •í•¨  
- ì„¤ì •ëœ ì¢Œí‘œê³„ë¥¼ **ì£¼ì„±ë¶„(Principal Component)**ì´ë¼ í•˜ë©°, ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ ì°¨ì›ì„ ì¶•ì†Œí•˜ëŠ” ê²ƒì´ ëª©ì   

### **PCA ì ˆì°¨ + ì˜ˆì œ**
1ï¸âƒ£ **ë°ì´í„° í‘œì¤€í™”**  
   - íŠ¹ì„± ê°„ì˜ ìŠ¤ì¼€ì¼ ì°¨ì´ë¥¼ ì—†ì• ê¸° ìœ„í•´ **í‰ê· ì„ 0, í‘œì¤€í¸ì°¨ë¥¼ 1**ë¡œ ë³€í™˜  
   - ğŸ“Œ **ì˜ˆì œ (Python ì½”ë“œ)**  
     ```python
     from sklearn.preprocessing import StandardScaler
     import numpy as np

     # ì˜ˆì œ ë°ì´í„° (í•™ìƒ ìˆ˜í•™, ê³¼í•™ ì„±ì )
     data = np.array([[85, 90], [88, 85], [75, 80], [95, 95], [80, 75]])

     # í‘œì¤€í™”
     scaler = StandardScaler()
     data_std = scaler.fit_transform(data)
     print(data_std)
     ```

2ï¸âƒ£ **ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°**  
   - ë³€ìˆ˜ë“¤ ê°„ì˜ ê´€ê³„(ìƒê´€ì„±, ë¶„ì‚°)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” **ê³µë¶„ì‚° í–‰ë ¬** ê³„ì‚°  
   - ğŸ“Œ **ì˜ˆì œ**
     ```python
     cov_matrix = np.cov(data_std.T)
     print(cov_matrix)
     ```

3ï¸âƒ£ **ê³ ìœ ê°’(Eigenvalue)ê³¼ ê³ ìœ ë²¡í„°(Eigenvector) ê³„ì‚°**  
   - ê³µë¶„ì‚° í–‰ë ¬ì„ **ê³ ìœ ê°’ ë¶„í•´**í•˜ì—¬ ì£¼ì„±ë¶„ì˜ ë°©í–¥ê³¼ í¬ê¸° ê²°ì •  
   - ğŸ“Œ **ì˜ˆì œ**
     ```python
     from numpy.linalg import eig
     eigenvalues, eigenvectors = eig(cov_matrix)
     print("ê³ ìœ ê°’:", eigenvalues)
     print("ê³ ìœ ë²¡í„°:", eigenvectors)
     ```

4ï¸âƒ£ **ì£¼ì„±ë¶„ ì„ íƒ**  
   - ê³ ìœ ê°’ì´ í° ìˆœì„œëŒ€ë¡œ ì£¼ì„±ë¶„ì„ ì„ íƒ  
   - ë³´í†µ **ì „ì²´ ë¶„ì‚°ì˜ 80~90% ì´ìƒ**ì„ ì„¤ëª…í•˜ëŠ” ì£¼ì„±ë¶„ ê°œìˆ˜ë¥¼ ì„ íƒ  

5ï¸âƒ£ **ë°ì´í„° ë³€í™˜**  
   - **ê³ ìœ ë²¡í„° í–‰ë ¬**ì„ ì‚¬ìš©í•´ ì›ë˜ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ì¢Œí‘œê³„(ì£¼ì„±ë¶„ ê³µê°„)ë¡œ ë³€í™˜  
   - ğŸ“Œ **ì˜ˆì œ**
     ```python
     pca_data = np.dot(data_std, eigenvectors)
     print("PCA ë³€í™˜ ë°ì´í„°:", pca_data)
     ```

---

### **ğŸ“Š PCAë¥¼ ì‹¤ì œ ë°ì´í„°ì— ì ìš©í•´ë³´ê¸°**
```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
iris = load_iris()
X = iris.data  # íŠ¹ì„± ë°ì´í„°

# PCA ì ìš© (2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# ì‹œê°í™”
plt.figure(figsize=(8,6))
sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=iris.target, palette="Set1")
plt.xlabel("ì£¼ì„±ë¶„ 1")
plt.ylabel("ì£¼ì„±ë¶„ 2")
plt.title("Iris ë°ì´í„° PCA ë³€í™˜")
plt.show()
```
âœ… **ê²°ê³¼**: 4ì°¨ì› ë°ì´í„°ë¥¼ 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ì—¬ ì‹œê°í™” ê°€ëŠ¥

---

## **2. ì¸ê³µì‹ ê²½ë§(Artificial Neural Network, ANN)**

### ğŸ“Œ **ì‹ ê²½ë§ì´ë€?**
- **ìƒë¬¼í•™ì  ì‹ ê²½ë§(Neuron)ì˜ êµ¬ì¡°**ë¥¼ ë³¸ë–  ë§Œë“  ëª¨ë¸  
- **ì…ë ¥ì¸µ(Input Layer), ì€ë‹‰ì¸µ(Hidden Layer), ì¶œë ¥ì¸µ(Output Layer)**ìœ¼ë¡œ êµ¬ì„±ë¨  
- **í™œì„±í™” í•¨ìˆ˜(Activation Function)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ì • ì„ê³„ì¹˜ë¥¼ ë„˜ìœ¼ë©´ ë‹¤ìŒ ì¸µìœ¼ë¡œ ì‹ í˜¸ ì „ë‹¬  

---

### **1ï¸âƒ£ ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)**
- **ì´ì§„ ë¶„ë¥˜(Binary Classification)** ëª¨ë¸  
- ğŸ“Œ **ì˜ˆì œ (MNIST ìˆ«ì ì´ë¯¸ì§€ ë¶„ë¥˜ - ë¡œì§€ìŠ¤í‹± íšŒê·€)**
  ```python
  from sklearn.linear_model import LogisticRegression
  from sklearn.datasets import load_digits
  from sklearn.model_selection import train_test_split
  from sklearn.metrics import accuracy_score

  # ë°ì´í„° ë¡œë“œ
  digits = load_digits()
  X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)

  # ëª¨ë¸ í•™ìŠµ
  model = LogisticRegression(max_iter=10000)
  model.fit(X_train, y_train)

  # ì˜ˆì¸¡ ë° ì •í™•ë„ í‰ê°€
  y_pred = model.predict(X_test)
  print("ë¡œì§€ìŠ¤í‹± íšŒê·€ ì •í™•ë„:", accuracy_score(y_test, y_pred))
  ```
âœ… **ê²°ê³¼**: ìˆ«ì ì¸ì‹ ì„±ëŠ¥ í™•ì¸ ê°€ëŠ¥  

---

### **2ï¸âƒ£ ì¸ê³µì‹ ê²½ë§(ANN) ëª¨ë¸ êµ¬í˜„**
- ğŸ“Œ **ì˜ˆì œ (Fashion MNIST ë°ì´í„° - ì‹ ê²½ë§ ì ìš©)**
  ```python
  import tensorflow as tf
  from tensorflow.keras import layers, models
  from tensorflow.keras.datasets import fashion_mnist
  import matplotlib.pyplot as plt

  # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()
  X_train, X_test = X_train / 255.0, X_test / 255.0  # ì •ê·œí™”

  # ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
  model = models.Sequential([
      layers.Flatten(input_shape=(28, 28)),  # 2D ì´ë¯¸ì§€ë¥¼ 1Dë¡œ ë³€í™˜
      layers.Dense(128, activation='relu'),  # ì€ë‹‰ì¸µ
      layers.Dense(10, activation='softmax') # ì¶œë ¥ì¸µ (10ê°œ í´ë˜ìŠ¤)
  ])

  # ëª¨ë¸ ì»´íŒŒì¼
  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

  # ëª¨ë¸ í•™ìŠµ
  model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

  # ëª¨ë¸ í‰ê°€
  test_loss, test_acc = model.evaluate(X_test, y_test)
  print("ì‹ ê²½ë§ í…ŒìŠ¤íŠ¸ ì •í™•ë„:", test_acc)
  ```
âœ… **ê²°ê³¼**: íŒ¨ì…˜ MNIST ë¶„ë¥˜ ì„±ëŠ¥ í™•ì¸ ê°€ëŠ¥  

---

## **3. PCAì™€ ì‹ ê²½ë§ ê²°í•©í•˜ê¸°**
1ï¸âƒ£ PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¨ì› ì¶•ì†Œ  
2ï¸âƒ£ ì¶•ì†Œëœ ë°ì´í„°ë¥¼ ì‹ ê²½ë§(ANN)ì— ì…ë ¥  
3ï¸âƒ£ ì—°ì‚°ëŸ‰ì„ ì¤„ì´ê³  ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµ  

ğŸ“Œ **PCA + ANN ì˜ˆì œ**
```python
# PCA ì ìš©
pca = PCA(n_components=50)  # 784ì°¨ì› â†’ 50ì°¨ì› ì¶•ì†Œ
X_train_pca = pca.fit_transform(X_train.reshape(-1, 28*28))
X_test_pca = pca.transform(X_test.reshape(-1, 28*28))

# ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
model = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(50,)),  # ì…ë ¥ ì°¨ì› ë³€ê²½
    layers.Dense(10, activation='softmax')
])

# ëª¨ë¸ í•™ìŠµ
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train_pca, y_train, epochs=10, validation_data=(X_test_pca, y_test))
```
âœ… **ê²°ê³¼**: PCAë¡œ ì¶•ì†Œ í›„ ANN ì ìš©í•˜ì—¬ ì„±ëŠ¥ í‰ê°€ ê°€ëŠ¥  

---

## **4. ìš”ì•½**
âœ… **PCA(ì£¼ì„±ë¶„ ë¶„ì„)**:  
- ë°ì´í„°ì˜ ì°¨ì›ì„ ì¶•ì†Œí•˜ì—¬ ì£¼ìš” ì •ë³´ë¥¼ ë³´ì¡´í•˜ëŠ” ê¸°ë²•  
- **ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨**ì„ í†µí•´ ì£¼ì„±ë¶„ ê°œìˆ˜ ê²°ì •  
- **ë¶„ë¥˜ê¸°ì™€ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥í•˜ë‚˜ ì„±ëŠ¥ì´ ë‚®ì•„ì§ˆ ìˆ˜ë„ ìˆìŒ**  

âœ… **ì¸ê³µì‹ ê²½ë§(ANN)**:  
- ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (MLP) êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ì„ í˜• ë¬¸ì œ í•´ê²°  
- ë”¥ëŸ¬ë‹(Deep Learning)ì˜ ê¸°ì´ˆ  

âœ… **PCA + ì‹ ê²½ë§ ì¡°í•© ê°€ëŠ¥**  
- **PCAë¡œ ì°¨ì›ì„ ì¤„ì´ê³  ANNì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ ë¹„êµ ê°€ëŠ¥**  
- ê³„ì‚°ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ë„ ìˆìŒ  

ì´ì œ PCAì™€ ì‹ ê²½ë§ì„ ì‹¤ì œ ë°ì´í„°ì— í™œìš©í•´ì„œ ì‹¤í—˜í•´ë³´ë©´ ì¢‹ì„ ê²ƒì„! ğŸš€


