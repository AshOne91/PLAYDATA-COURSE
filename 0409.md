ResNet
```
ResNet : 스킵구조를 이용한 CNN
기울기 소실 : 은닉층이 깊어져서  가중치들의 기울기가 0에 가까워지는 현상 - 더이상 업데이트 안됨
학습도중에 파악하기 어려움(기울기소실되었는지 학습이 잘되서 최적의 값에 수렴한것인지)

배치정규화 : 배치간의 차이를 정규화해서 학습을 더 안정적으로

스킵커넥션 : 은닉층을 거치지 않고 입력값과 은닉층의 결과를 더하는 구조

데이터 : CIAR10
```
ResNet(Residual Network)은 **딥러닝 모델이 깊어질수록 발생하는 학습 문제**, 특히 **기울기 소실 문제**를 해결하기 위해 제안된 구조임. 자세히 설명하면 다음과 같음:

---

### 📌 ResNet 학습 목적 상세

---

#### ✅ 1. 기울기 소실 문제 (Vanishing Gradient Problem)

- 은닉층이 깊어질수록 역전파 과정에서 **기울기(gradient)**가 계속 작아져서 **초기 층들의 가중치가 거의 갱신되지 않음.**
- 이로 인해 **학습이 진행되지 않거나 매우 느려짐.**
- ResNet은 **이 문제를 근본적으로 해결**하고 **100개 이상의 층**도 안정적으로 학습 가능하게 해줌.

---

#### ✅ 2. 스킵 커넥션(Skip Connection = Residual Connection)

- 핵심 아이디어: **입력값을 은닉층의 출력과 더함**
  
  수식:  
  \[
  y = F(x) + x
  \]  
  여기서 \(F(x)\)는 convolution, batch normalization, activation 등을 거친 결과이고  
  \(x\)는 그대로 전달되는 입력임

- 이 구조의 장점:
  - **기울기가 더 직접적으로 전달되어 깊은 네트워크도 학습 가능**
  - **정보 손실 방지**: 입력 정보를 직접 다음 블록에 전달
  - **빠른 수렴**과 **높은 정확도**

---

#### ✅ 3. 배치 정규화(Batch Normalization)

- 학습 시, 각 층의 입력 분포를 정규화하여 **학습을 안정화**하고 **속도 향상**
- ResNet은 각 블록 안에서 Conv → BN → ReLU 순서로 사용됨
- 과적합 방지 효과도 일부 있음

---

#### ✅ 4. CIFAR-10 데이터셋 사용

- 이미지 분류용 소형 데이터셋 (32x32, RGB 컬러 이미지 10종류)
- 클래스:
  ```
  airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck
  ```
- ResNet 구조 실습에 적합함 (빠른 실험 가능)

---

### 🧱 ResNet 구조 구성요소 요약

| 구성 요소           | 설명 |
|--------------------|------|
| Conv Block         | Conv → BN → ReLU |
| Residual Block     | Conv Block + Skip Connection |
| Downsampling Block | Stride > 1 or 1x1 Conv for dimension match |
| GlobalAvgPooling   | 전역 평균 풀링으로 FC대신 사용 |
| Dense Layer        | 마지막 Softmax 출력층 (클래스 수만큼 출력) |

---

### 🔧 실습 시 주요 구성 방식 (예: ResNet-18)

```python
def residual_block(x, filters, downsample=False):
    shortcut = x
    stride = 2 if downsample else 1

    x = layers.Conv2D(filters, 3, strides=stride, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(filters, 3, strides=1, padding='same')(x)
    x = layers.BatchNormalization()(x)

    if downsample:
        shortcut = layers.Conv2D(filters, 1, strides=2, padding='same')(shortcut)

    x = layers.add([x, shortcut])
    x = layers.ReLU()(x)
    return x
```

---

### 🎯 학습 목표 요약

| 목표 항목              | 설명 |
|-----------------------|------|
| 깊은 네트워크에서 학습 안정화 이해 | 기울기 소실 문제 해결 방법 이해 |
| 스킵 연결 효과 분석    | 모델 성능 및 수렴 속도 향상 이해 |
| BN의 역할과 위치 이해 | 학습 안정성 확보 |
| CIFAR-10을 통한 실습  | ResNet을 실제로 구현하며 구조 이해 |

---

필요하면 ResNet-18/34/50의 블록 구조부터 CIFAR-10 적용 코드까지 단계별로 상세히 정리해줄 수 있음.  
어떤 단계부터 정리해줄까? 예:  
1️⃣ 블록 구조 시각화  
2️⃣ 전체 네트워크 설계  
3️⃣ CIFAR-10 적용  
4️⃣ 성능 평가  
5️⃣ 커스텀 ResNet 만들기

배치 정규화(Batch Normalization)는 **딥러닝 모델의 학습을 안정적으로 만들고, 수렴 속도를 높이며, 과적합을 줄여주는 정규화 기법**임. 아래는 학습 목적에 맞게 **매우 자세하게** 정리한 내용임:

---

## 📘 배치 정규화(Batch Normalization, BN)

---

### ✅ 1. 배경

#### 🔺 왜 필요한가?

- 신경망이 깊어질수록 **파라미터 초기화나 학습률 설정이 까다로워짐**
- 은닉층의 입력값 분포가 **학습 중 계속 바뀌는 문제** 발생 → **Internal Covariate Shift**
- 이로 인해 **학습 속도 느림**, **기울기 소실**, **불안정한 학습** 발생

---

### ✅ 2. 핵심 아이디어

> **"각 미니배치마다 입력을 정규화(Normalization)하자!"**

즉, 각 배치마다 각 뉴런의 입력값을 평균 0, 표준편차 1로 정규화함.

정규화 수식:

\[
\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i \quad \text{(배치 평균)}
\]
\[
\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2 \quad \text{(배치 분산)}
\]
\[
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} \quad \text{(정규화)}
\]

\[
y_i = \gamma \hat{x}_i + \beta \quad \text{(스케일링 및 쉬프팅)}
\]

- \(\epsilon\): 분모가 0이 되는 것 방지 (작은 수)
- \(\gamma, \beta\): 학습 가능한 파라미터 → 네트워크가 필요시 원래 분포로 되돌릴 수 있음

---

### ✅ 3. 적용 위치

- 일반적으로 `Conv2D` 또는 `Dense` → `BatchNormalization()` → `ReLU` 순으로 적용
- 예시:

```python
x = Conv2D(32, kernel_size=3, padding='same')(x)
x = BatchNormalization()(x)
x = ReLU()(x)
```

---

### ✅ 4. 장점 요약

| 장점                     | 설명 |
|--------------------------|------|
| 🌟 학습 안정화            | 입력 분포가 일정하게 유지되어 더 높은 학습률 사용 가능 |
| ⚡ 학습 속도 향상         | 빠른 수렴 가능 |
| 🧱 깊은 신경망 학습 가능  | 기울기 소실/폭발 감소 |
| ❌ Dropout 대체 가능      | 일부 경우 Regularization 효과가 커서 dropout 없이도 학습 가능 |
| 🧪 초기화 민감도 감소     | 초기 파라미터에 덜 민감함 |

---

### ✅ 5. 주의할 점

- 학습 시와 추론 시 동작 방식이 다름  
  - **학습 시:** 배치마다 평균/분산 계산  
  - **추론 시:** 학습 중 저장된 moving average 사용
- **RNN 계열에서는 적용이 까다로움** → Layer Normalization 사용

---

### ✅ 6. 실제 코드 예시 (TensorFlow)

```python
from tensorflow.keras import layers

def basic_block(x, filters):
    x = layers.Conv2D(filters, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)  # 정규화
    x = layers.ReLU()(x)
    return x
```

---

### ✅ 7. 실습 효과 (ResNet에서 BN이 주는 효과)

| Without BN | With BN |
|------------|---------|
| 학습 매우 느림 | 빠른 수렴 |
| 초기 학습률 작게 설정 필요 | 큰 학습률도 안정적 |
| 기울기 소실 쉽게 발생 | 깊은 네트워크도 학습 가능 |
| Dropout 필요 | 없어도 됨 (BN 자체에 정규화 효과 있음) |

---

필요하면 시각화된 예제나 실제 CIFAR10에서 BN이 있는 경우 vs 없는 경우의 실험 비교도 정리해줄 수 있음.  
다음 단계는 ResNet에 적용된 BN 구조 시각화 해볼까?

좋음. 지금부터 **ResNet 구조**와 그 안에서 사용되는 **핵심 개념들**을 **처음 배우는 사람** 기준으로 **천천히, 아주 상세하게** 설명하겠음.

---

## ✅ 1. 기본 CNN 개념부터 시작

---

### 📌 CNN(합성곱 신경망)이란?

CNN은 이미지 분류, 객체 인식 등에 자주 사용되는 신경망 구조임.  

주요 구성 요소는 다음과 같음:

| 층 종류 | 설명 |
|--------|------|
| **Conv2D** | 이미지에서 특징을 추출하는 필터 |
| **ReLU** | 비선형 함수. 음수 제거로 모델이 더 복잡한 것을 학습하게 만듦 |
| **Pooling** | 이미지를 작게 줄여 계산량을 줄이고, 중요한 특징만 남김 |
| **Flatten** | 2D 이미지 데이터를 1D 벡터로 펴줌 |
| **Fully Connected Layer** | 평탄화된 벡터로 최종 분류함 (Dense Layer) |

---

## ✅ 2. CNN이 깊어질수록 생기는 문제

---

### ❗ 기울기 소실(Vanishing Gradient)

- 신경망이 깊어질수록 **뒤쪽 레이어의 가중치만 업데이트**되고 **앞쪽은 거의 업데이트 안 되는 문제**가 생김.
- 이로 인해 앞단의 학습이 멈추게 되어, **모델 전체 성능이 낮아짐**.

---

## ✅ 3. ResNet이란?

---

### 📌 Residual Network의 줄임말

ResNet은 **기울기 소실 문제를 해결하기 위해 만든 구조**임.

핵심 아이디어는 **스킵 커넥션(Skip Connection)** 또는 **잔차 연결(Residual Connection)**을 도입하는 것임.

---

### 📌 스킵 커넥션(Skip Connection)이란?

일반적으로 CNN은 이렇게 연결됨:

```
입력 → Conv → ReLU → Conv → ReLU → 출력
```

하지만 ResNet은 **입력을 그대로 우회시켜 출력에 더함**:

```
입력 ────────┐
             ↓
        Conv → ReLU → Conv
             ↓
         출력 + 입력  → ReLU → 최종 출력
```

즉, 입력을 **은닉층을 거치지 않고 바로 결과에 더함**.

---

### ✨ 왜 이런 구조가 좋을까?

- 신경망이 깊어져도, **입력 정보를 잃지 않고 직접 전달**됨.
- 덧셈 연산은 **기울기를 앞쪽까지 전달**하기 쉬움 ⇒ **기울기 소실 해결**
- 학습이 더 빨라지고, 더 깊은 네트워크 학습이 가능해짐

---

## ✅ 4. 배치 정규화(Batch Normalization)

---

### 📌 뭐하는 애?

- CNN에서 **각 레이어마다 들어가는 값의 분포를 정규화**해줌 (평균 0, 분산 1로 맞춤)
- 학습할 때 **값이 갑자기 커지거나 작아지는 것 방지**
- **속도 향상**, **수렴 안정화**, **과적합 방지** 효과가 있음

---

### ✋ 예시로 이해

만약 어떤 층의 출력이 `[10, 100, 500]`처럼 되면, 다음 층이 이 값을 처리하기 어려움.  
배치 정규화는 이것을 `[0.1, 0.2, 0.3]`처럼 **고르게 정규화**해줘서 학습을 원활하게 만듦.

---

## ✅ 5. Residual Block 요약

### 구조:

```
입력 x
│
├─ Conv → BN → ReLU → Conv → BN
│
└───────────────(x 그대로 더함)
│
ReLU
│
출력
```

- Conv: 특징 추출
- BN: 정규화
- ReLU: 비선형화
- Skip Connection: 입력 그대로 더해서 정보 손실 방지

---

## ✅ 6. HResNet 예제 구조 요약

```text
[입력 3x32x32]
↓
Block1 (3→64) + Pooling → 16x16
↓
Block2 (64→128) + Pooling → 8x8
↓
Block3 (128→256) + Pooling → 4x4
↓
Flatten → FC1(2048) → ReLU
↓
FC2(512) → ReLU
↓
FC3(10) → 클래스 예측
```

---

## ✅ 7. 전체 흐름 그림 요약

```text
이미지 입력
   ↓
[ Residual Block 1 ]
   ↓
[ Residual Block 2 ]
   ↓
[ Residual Block 3 ]
   ↓
평탄화 (Flatten)
   ↓
Fully Connected Layers
   ↓
소프트맥스 (클래스 예측)
```

---

## ✅ 8. 학습 목적 요약

| 목적 | 설명 |
|------|------|
| 🔍 **깊은 신경망에서 기울기 소실 해결** | Skip Connection 도입 |
| ⚙️ **학습 안정화 및 빠른 수렴** | Batch Normalization 사용 |
| 📊 **이미지 분류 정확도 향상** | CIFAR-10 10개 클래스를 분류 |
| 💡 **실제 ResNet 구조 연습** | ResNet 원리를 이해하고 구현 능력 향상 |

---

필요하다면 `ResNet50`, `ResNet101` 같은 실제 이미지넷용 ResNet 구조도 설명 가능함.  
또한, 현재 구조로 실제 학습 돌리는 PyTorch 학습 루프도 설명 가능함. 요청해줘.

좋음.  
전체 코드는 PyTorch를 사용하여 **ResNet 스타일 CNN을 CIFAR-10 이미지 분류에 학습시키는 코드**임.  
기초부터 차근차근 전체 흐름과 목적, 각 코드의 역할을 **완전 초보자 관점에서 상세하게** 설명함.

---

## 🧠 1. 전체 구조 개요  

### 이 코드는 크게 3단계로 나뉨:
1. **모델 정의** (`BasicBlock`, `HResNet`)
2. **데이터 준비** (CIFAR-10 로딩 및 전처리)
3. **훈련 루프** (학습, 손실 계산, 최적화)

---

## 🔧 2. 모델 정의 - ResNet 구조 만들기

```python
class BasicBlock(nn.Module):
```
### ✅ `BasicBlock` : ResNet에서 사용되는 기본 구성 단위 (Residual Block)

#### 주요 구조:
- Conv → BN → ReLU → Conv → BN  
- 그리고, 입력을 **스킵(skip)**해서 마지막 결과와 더함.  
→ 이것이 **Residual Connection** 또는 **Skip Connection**이라 부름.  
→ 목적: **기울기 소실 문제를 줄이고, 학습을 더 깊은 네트워크로도 가능하게 함**

```python
    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
```
- 두 개의 3x3 Convolution Layer
- `padding=1`은 출력 크기 유지를 위한 것임

```python
    self.bn1 = nn.BatchNorm2d(out_channels)
    self.bn2 = nn.BatchNorm2d(out_channels)
```
- **BatchNorm**: 각 배치에서 값들을 평균 0, 분산 1로 정규화하여 학습 안정화

```python
    self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1)
```
- 입력 채널 수가 바뀌는 경우 (ex. 3→64), 크기를 맞춰주기 위한 1x1 convolution

---

### ✅ `forward` 함수의 흐름

```python
    x_ = x  # 스킵커넥션을 위해 원래 입력 저장
    x = self.bn1(self.conv1(x))
    x = self.relu(x)
    x = self.bn2(self.conv2(x))
    x_ = self.downsample(x_)  # 채널 수 맞추기
    x += x_  # 스킵 연결
    return self.relu(x)
```

---

## 🧱 `HResNet`: CNN 전체 구조

```python
self.b1 = BasicBlock(3, 64)
self.b2 = BasicBlock(64, 128)
self.b3 = BasicBlock(128, 256)
```
- 세 개의 Residual Block 사용  
- 입력 이미지가 (3채널, 32x32)이므로, 처음엔 3 → 64로 변환  

```python
self.pool = nn.AvgPool2d(kernel_size=2, stride=2)
```
- **2x2 평균 풀링**으로 **크기를 절반으로 줄임**  
  - (32x32 → 16x16 → 8x8 → 4x4)

---

### ✅ Fully Connected Layer (분류기)

```python
self.fc1 = nn.Linear(256*4*4, 2048)
self.fc2 = nn.Linear(2048, 512)
self.fc3 = nn.Linear(512, 10)
```
- 마지막에는 평탄화 → 분류기 통과 → **10개의 클래스 (CIFAR-10)** 확률 출력

---

## 📦 3. 데이터 불러오기

```python
from torchvision.datasets.cifar import CIFAR10
```
- CIFAR-10: 10종류(비행기, 자동차 등)의 32x32 RGB 이미지 6만 장 (5만 훈련, 1만 테스트)

```python
transforms = Compose([ToTensor(), Normalize(mean=(0.5,...), std=(0.25,...)])
```
- 이미지를 **Tensor로 바꾸고**, 정규화 수행  
  - 평균 0, 분산 1 근처로 만들어 학습 안정화

```python
cifar10_train_loader = DataLoader(cifar10_train_dataset, batch_size=128, shuffle=True)
```
- 데이터셋을 batch 단위로 묶고, 학습용은 `shuffle=True`

---

## 🧪 4. 학습 (Train)

```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'
```
- GPU 사용 가능하면 `cuda`, 아니면 `cpu`

```python
loss_fn = nn.CrossEntropyLoss()
optim = torch.optim.Adam(hresnet.parameters(), lr=1e-4)
```
- 손실 함수: **CrossEntropy** (다중 클래스 분류)
- 옵티마이저: **Adam** (가장 많이 쓰이는 최적화 알고리즘 중 하나)

---

### 🔁 학습 루프

```python
for epoch in range(epochs):
  for data, label in cifar10_train_loader:
    ...
```

#### 1. 데이터 GPU로 전송
```python
data, label = data.to(device), label.to(device)
```

#### 2. 예측
```python
predict = hresnet(data)
```

#### 3. 손실 계산
```python
loss = loss_fn(predict, label)
```

#### 4. 역전파
```python
loss.backward()
```

#### 5. 가중치 업데이트
```python
optim.step()
```

#### 6. 그래디언트 초기화 (다음 반복 위해)
```python
optim.zero_grad()
```

---

## ✅ 결과
- 이 코드는 30 에폭 동안 CIFAR-10 데이터에 대해 **ResNet 구조의 CNN을 학습시켜 분류 정확도를 높이는 작업**임.

---

## 📌 처음 공부하는 입장에서 기억해야 할 핵심

| 개념 | 설명 |
|------|------|
| **Conv2D** | 이미지 특징 추출 |
| **BatchNorm** | 학습 안정화 (평균 0, 분산 1) |
| **ReLU** | 비선형성 부여 |
| **Skip Connection** | 입력을 직접 더해서 깊은 모델 학습 가능하게 |
| **AvgPool** | 이미지 크기 줄이기 |
| **Flatten** | 이미지 → 벡터 변환 |
| **Linear** | 마지막 분류기 |
| **CrossEntropyLoss** | 다중 클래스 분류에 적합 |
| **Adam Optimizer** | 빠르고 안정적인 최적화 알고리즘 |

---

필요하면 이 구조를 **시각적으로 그려주거나**,  
**훈련 정확도/손실 시각화 코드**도 추가로 설명 가능함.  
추가 요청할 내용 있으면 말해줘.

좋음. 아래는 당신이 작성한 전체 코드의 **구조와 흐름을 초보자 기준으로 아주 자세히** 한 줄 한 줄 설명함.  

지금까지 작성한 코드는 크게 다음과 같이 구성되어 있음:

---

## ✅ 1. CIFAR-10 데이터셋 불러오기 및 전처리

```python
from torchvision.datasets.cifar import CIFAR10
from torch.utils.data import DataLoader
from torchvision.transforms import Compose, ToTensor, Normalize
```

- `torchvision.datasets.cifar.CIFAR10`: CIFAR-10이라는 10가지 클래스(자동차, 개구리, 고양이 등)를 가진 이미지 데이터셋을 불러오는 클래스.
- `DataLoader`: 데이터셋을 한 번에 처리하기 좋은 **작은 묶음(batch)** 으로 잘라서 GPU로 보내줄 수 있게 해주는 도구.
- `Compose`, `ToTensor`, `Normalize`: 이미지를 **전처리(데이터 정리)** 하기 위한 함수들.

```python
transforms = Compose([
    ToTensor(),  # 이미지를 Tensor(숫자 행렬)로 바꿈 (0~255 → 0.0~1.0)
    Normalize(mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25))  # 정규화(데이터 분포를 평균 0, 표준편차 1로 맞춤)
])
```

```python
# 훈련용 데이터셋
cifar10_train_dataset = CIFAR10(root='./', train=True, download=True, transform=transforms)

# 테스트용 데이터셋
cifar10_test_dataset = CIFAR10(root='./', train=False, download=True, transform=transforms)
```

- `root='./'`: 데이터를 현재 디렉토리에 저장.
- `train=True/False`: 학습용(train), 시험용(test)으로 나누는 옵션.
- `download=True`: 처음 실행 시 인터넷에서 데이터를 다운받음.

```python
# 데이터를 묶음 단위(batch_size=128)로 로딩하고, 훈련용은 섞음(shuffle)
cifar10_train_loader = DataLoader(cifar10_train_dataset, batch_size=128, shuffle=True)
cifar10_test_loader = DataLoader(cifar10_test_dataset, batch_size=128)
```

---

## ✅ 2. 학습 루프 함수 정의

```python
def train(model):
```

- 모델을 파라미터로 받아서 학습시키는 함수 정의.

```python
  device = 'cuda' if torch.cuda.is_available() else 'cpu'
```

- GPU가 있으면 `'cuda'`, 없으면 `'cpu'`. 모델과 데이터를 어디서 계산할지 설정.

```python
  lr = 1e-4  # 학습률(learning rate)
  epochs = 30  # 전체 에폭 수
```

- 학습률: 가중치를 얼마나 빠르게 수정할지 결정.
- 에폭: 전체 데이터를 몇 번 반복해서 학습할 것인지.

```python
  from tqdm import tqdm  # 진행 상황을 시각적으로 보여주는 도구
```

```python
  loss_fn = nn.CrossEntropyLoss()  # 분류 문제에서 사용하는 손실 함수
  optim = torch.optim.Adam(model.parameters(), lr=lr)  # Adam 최적화기 사용
```

```python
  for epoch in range(epochs):
    epoch_loss = 0.0  # 에폭마다 손실 누적
    iterator = tqdm(cifar10_train_loader)  # 진행 표시줄 만들기
```

```python
    for data, label in iterator:
      data, label = data.to(device), label.to(device)  # 데이터를 GPU로 이동
```

```python
      predict = model(data)  # 모델이 예측한 결과값
      loss = loss_fn(predict, label)  # 예측값과 실제값의 차이 계산
      loss.backward()  # 오차를 역전파하여 가중치 미분 계산
      optim.step()  # 가중치 업데이트
      optim.zero_grad()  # 다음 배치를 위해 미분값 초기화
      epoch_loss += loss.item()  # 손실값 누적
      iterator.set_description(f'loss : {loss.item()}')  # 진행창에 손실값 표시
```

```python
    print(f'epoch:{epoch+1} loss : {epoch_loss/len(cifar10_train_loader)}')
```

---

## ✅ 3. HResNet 평가

```python
hresnet.eval()  # 평가 모드 (BatchNorm, Dropout 비활성화)
total_corr = 0  # 정답 개수 저장용
```

```python
with torch.no_grad():  # 평가 중에는 기울기 계산이 필요 없음 → 메모리 절약
  for data, label in cifar10_test_loader:
    data, label = data.to(device), label.to(device)
    predict = hresnet(data)
    pred = predict.data.max(dim=1)[1]  # 가장 높은 점수를 가진 클래스 선택
    corr = pred.eq(label).sum().item()  # 정답 비교해서 맞춘 개수 계산
    total_corr += corr
print(f'accuracy : {total_corr / len(cifar10_test_loader.dataset)}')  # 전체 정확도
```

---

## ✅ 4. 한 배치 평가 샘플

```python
data, label = next(iter(cifar10_test_loader))  # 테스트 데이터 하나의 배치 꺼냄
data, label = data.to(device), label.to(device)
hresnet.eval()
predict = hresnet(data)
predict.max(dim=1)[1].eq(label).sum().item() / len(label)  # 해당 배치의 정확도
```

---

## ✅ 5. 전이 학습 모델 로딩 및 학습

```python
from torchvision.models import resnet18, ResNet18_Weights
device = 'cuda' if torch.cuda.is_available() else 'cpu'
```

```python
res18 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
```

- `resnet18`: ImageNet에서 미리 학습된 ResNet-18 모델을 불러옴.  
- `weights`: 미리 학습된 가중치 로드.

```python
res18.fc = nn.Linear(in_features=512, out_features=10, bias=True)
```

- 마지막 출력층을 CIFAR-10에 맞게 `10개 클래스`로 변경.

```python
res18.to(device)
```

- 모델을 GPU 또는 CPU로 이동.

```python
for param in res18.parameters():
  param.requires_grad = False
for param in res18.fc.parameters():
  param.requires_grad = True
```

- 미리 학습된 가중치는 고정하고(`requires_grad = False`), **새로 학습해야 하는 fc층만 학습하도록 설정**.

---

## ✅ 6. 전이 학습 모델 학습 실행

```python
train(res18)
```

- 위에서 만든 `train()` 함수에 ResNet-18 모델을 넣어서 훈련 시작.

---

## 🔚 요약 흐름

1. CIFAR-10 데이터셋 로딩
2. 이미지 전처리 (`ToTensor`, `Normalize`)
3. `train()` 함수 정의
4. 커스텀 모델(HResNet) 학습 및 평가
5. 전이학습 모델(ResNet-18) 불러오기 + 분류층 수정
6. `train()` 함수 재사용해 학습

---

필요하면:
- 예측 시 이미지 시각화
- 혼동 행렬 출력
- 모델 저장 및 불러오기  
이런 것도 추가해줄 수 있음.  
원하는 내용 이어서 알려주면 다음 진행 도와줌.
