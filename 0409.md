ResNet
```
ResNet : ìŠ¤í‚µêµ¬ì¡°ë¥¼ ì´ìš©í•œ CNN
ê¸°ìš¸ê¸° ì†Œì‹¤ : ì€ë‹‰ì¸µì´ ê¹Šì–´ì ¸ì„œ  ê°€ì¤‘ì¹˜ë“¤ì˜ ê¸°ìš¸ê¸°ê°€ 0ì— ê°€ê¹Œì›Œì§€ëŠ” í˜„ìƒ - ë”ì´ìƒ ì—…ë°ì´íŠ¸ ì•ˆë¨
í•™ìŠµë„ì¤‘ì— íŒŒì•…í•˜ê¸° ì–´ë ¤ì›€(ê¸°ìš¸ê¸°ì†Œì‹¤ë˜ì—ˆëŠ”ì§€ í•™ìŠµì´ ì˜ë˜ì„œ ìµœì ì˜ ê°’ì— ìˆ˜ë ´í•œê²ƒì¸ì§€)

ë°°ì¹˜ì •ê·œí™” : ë°°ì¹˜ê°„ì˜ ì°¨ì´ë¥¼ ì •ê·œí™”í•´ì„œ í•™ìŠµì„ ë” ì•ˆì •ì ìœ¼ë¡œ

ìŠ¤í‚µì»¤ë„¥ì…˜ : ì€ë‹‰ì¸µì„ ê±°ì¹˜ì§€ ì•Šê³  ì…ë ¥ê°’ê³¼ ì€ë‹‰ì¸µì˜ ê²°ê³¼ë¥¼ ë”í•˜ëŠ” êµ¬ì¡°

ë°ì´í„° : CIAR10
```
ResNet(Residual Network)ì€ **ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ë°œìƒí•˜ëŠ” í•™ìŠµ ë¬¸ì œ**, íŠ¹íˆ **ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œ**ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆëœ êµ¬ì¡°ì„. ìì„¸íˆ ì„¤ëª…í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŒ:

---

### ğŸ“Œ ResNet í•™ìŠµ ëª©ì  ìƒì„¸

---

#### âœ… 1. ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œ (Vanishing Gradient Problem)

- ì€ë‹‰ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ì—­ì „íŒŒ ê³¼ì •ì—ì„œ **ê¸°ìš¸ê¸°(gradient)**ê°€ ê³„ì† ì‘ì•„ì ¸ì„œ **ì´ˆê¸° ì¸µë“¤ì˜ ê°€ì¤‘ì¹˜ê°€ ê±°ì˜ ê°±ì‹ ë˜ì§€ ì•ŠìŒ.**
- ì´ë¡œ ì¸í•´ **í•™ìŠµì´ ì§„í–‰ë˜ì§€ ì•Šê±°ë‚˜ ë§¤ìš° ëŠë ¤ì§.**
- ResNetì€ **ì´ ë¬¸ì œë¥¼ ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°**í•˜ê³  **100ê°œ ì´ìƒì˜ ì¸µ**ë„ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ í•´ì¤Œ.

---

#### âœ… 2. ìŠ¤í‚µ ì»¤ë„¥ì…˜(Skip Connection = Residual Connection)

- í•µì‹¬ ì•„ì´ë””ì–´: **ì…ë ¥ê°’ì„ ì€ë‹‰ì¸µì˜ ì¶œë ¥ê³¼ ë”í•¨**
  
  ìˆ˜ì‹:  
  \[
  y = F(x) + x
  \]  
  ì—¬ê¸°ì„œ \(F(x)\)ëŠ” convolution, batch normalization, activation ë“±ì„ ê±°ì¹œ ê²°ê³¼ì´ê³   
  \(x\)ëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬ë˜ëŠ” ì…ë ¥ì„

- ì´ êµ¬ì¡°ì˜ ì¥ì :
  - **ê¸°ìš¸ê¸°ê°€ ë” ì§ì ‘ì ìœ¼ë¡œ ì „ë‹¬ë˜ì–´ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë„ í•™ìŠµ ê°€ëŠ¥**
  - **ì •ë³´ ì†ì‹¤ ë°©ì§€**: ì…ë ¥ ì •ë³´ë¥¼ ì§ì ‘ ë‹¤ìŒ ë¸”ë¡ì— ì „ë‹¬
  - **ë¹ ë¥¸ ìˆ˜ë ´**ê³¼ **ë†’ì€ ì •í™•ë„**

---

#### âœ… 3. ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)

- í•™ìŠµ ì‹œ, ê° ì¸µì˜ ì…ë ¥ ë¶„í¬ë¥¼ ì •ê·œí™”í•˜ì—¬ **í•™ìŠµì„ ì•ˆì •í™”**í•˜ê³  **ì†ë„ í–¥ìƒ**
- ResNetì€ ê° ë¸”ë¡ ì•ˆì—ì„œ Conv â†’ BN â†’ ReLU ìˆœì„œë¡œ ì‚¬ìš©ë¨
- ê³¼ì í•© ë°©ì§€ íš¨ê³¼ë„ ì¼ë¶€ ìˆìŒ

---

#### âœ… 4. CIFAR-10 ë°ì´í„°ì…‹ ì‚¬ìš©

- ì´ë¯¸ì§€ ë¶„ë¥˜ìš© ì†Œí˜• ë°ì´í„°ì…‹ (32x32, RGB ì»¬ëŸ¬ ì´ë¯¸ì§€ 10ì¢…ë¥˜)
- í´ë˜ìŠ¤:
  ```
  airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck
  ```
- ResNet êµ¬ì¡° ì‹¤ìŠµì— ì í•©í•¨ (ë¹ ë¥¸ ì‹¤í—˜ ê°€ëŠ¥)

---

### ğŸ§± ResNet êµ¬ì¡° êµ¬ì„±ìš”ì†Œ ìš”ì•½

| êµ¬ì„± ìš”ì†Œ           | ì„¤ëª… |
|--------------------|------|
| Conv Block         | Conv â†’ BN â†’ ReLU |
| Residual Block     | Conv Block + Skip Connection |
| Downsampling Block | Stride > 1 or 1x1 Conv for dimension match |
| GlobalAvgPooling   | ì „ì—­ í‰ê·  í’€ë§ìœ¼ë¡œ FCëŒ€ì‹  ì‚¬ìš© |
| Dense Layer        | ë§ˆì§€ë§‰ Softmax ì¶œë ¥ì¸µ (í´ë˜ìŠ¤ ìˆ˜ë§Œí¼ ì¶œë ¥) |

---

### ğŸ”§ ì‹¤ìŠµ ì‹œ ì£¼ìš” êµ¬ì„± ë°©ì‹ (ì˜ˆ: ResNet-18)

```python
def residual_block(x, filters, downsample=False):
    shortcut = x
    stride = 2 if downsample else 1

    x = layers.Conv2D(filters, 3, strides=stride, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)

    x = layers.Conv2D(filters, 3, strides=1, padding='same')(x)
    x = layers.BatchNormalization()(x)

    if downsample:
        shortcut = layers.Conv2D(filters, 1, strides=2, padding='same')(shortcut)

    x = layers.add([x, shortcut])
    x = layers.ReLU()(x)
    return x
```

---

### ğŸ¯ í•™ìŠµ ëª©í‘œ ìš”ì•½

| ëª©í‘œ í•­ëª©              | ì„¤ëª… |
|-----------------------|------|
| ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œ í•™ìŠµ ì•ˆì •í™” ì´í•´ | ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œ í•´ê²° ë°©ë²• ì´í•´ |
| ìŠ¤í‚µ ì—°ê²° íš¨ê³¼ ë¶„ì„    | ëª¨ë¸ ì„±ëŠ¥ ë° ìˆ˜ë ´ ì†ë„ í–¥ìƒ ì´í•´ |
| BNì˜ ì—­í• ê³¼ ìœ„ì¹˜ ì´í•´ | í•™ìŠµ ì•ˆì •ì„± í™•ë³´ |
| CIFAR-10ì„ í†µí•œ ì‹¤ìŠµ  | ResNetì„ ì‹¤ì œë¡œ êµ¬í˜„í•˜ë©° êµ¬ì¡° ì´í•´ |

---

í•„ìš”í•˜ë©´ ResNet-18/34/50ì˜ ë¸”ë¡ êµ¬ì¡°ë¶€í„° CIFAR-10 ì ìš© ì½”ë“œê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ìƒì„¸íˆ ì •ë¦¬í•´ì¤„ ìˆ˜ ìˆìŒ.  
ì–´ë–¤ ë‹¨ê³„ë¶€í„° ì •ë¦¬í•´ì¤„ê¹Œ? ì˜ˆ:  
1ï¸âƒ£ ë¸”ë¡ êµ¬ì¡° ì‹œê°í™”  
2ï¸âƒ£ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ì„¤ê³„  
3ï¸âƒ£ CIFAR-10 ì ìš©  
4ï¸âƒ£ ì„±ëŠ¥ í‰ê°€  
5ï¸âƒ£ ì»¤ìŠ¤í…€ ResNet ë§Œë“¤ê¸°

ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)ëŠ” **ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•™ìŠµì„ ì•ˆì •ì ìœ¼ë¡œ ë§Œë“¤ê³ , ìˆ˜ë ´ ì†ë„ë¥¼ ë†’ì´ë©°, ê³¼ì í•©ì„ ì¤„ì—¬ì£¼ëŠ” ì •ê·œí™” ê¸°ë²•**ì„. ì•„ë˜ëŠ” í•™ìŠµ ëª©ì ì— ë§ê²Œ **ë§¤ìš° ìì„¸í•˜ê²Œ** ì •ë¦¬í•œ ë‚´ìš©ì„:

---

## ğŸ“˜ ë°°ì¹˜ ì •ê·œí™”(Batch Normalization, BN)

---

### âœ… 1. ë°°ê²½

#### ğŸ”º ì™œ í•„ìš”í•œê°€?

- ì‹ ê²½ë§ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ **íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”ë‚˜ í•™ìŠµë¥  ì„¤ì •ì´ ê¹Œë‹¤ë¡œì›Œì§**
- ì€ë‹‰ì¸µì˜ ì…ë ¥ê°’ ë¶„í¬ê°€ **í•™ìŠµ ì¤‘ ê³„ì† ë°”ë€ŒëŠ” ë¬¸ì œ** ë°œìƒ â†’ **Internal Covariate Shift**
- ì´ë¡œ ì¸í•´ **í•™ìŠµ ì†ë„ ëŠë¦¼**, **ê¸°ìš¸ê¸° ì†Œì‹¤**, **ë¶ˆì•ˆì •í•œ í•™ìŠµ** ë°œìƒ

---

### âœ… 2. í•µì‹¬ ì•„ì´ë””ì–´

> **"ê° ë¯¸ë‹ˆë°°ì¹˜ë§ˆë‹¤ ì…ë ¥ì„ ì •ê·œí™”(Normalization)í•˜ì!"**

ì¦‰, ê° ë°°ì¹˜ë§ˆë‹¤ ê° ë‰´ëŸ°ì˜ ì…ë ¥ê°’ì„ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ì •ê·œí™”í•¨.

ì •ê·œí™” ìˆ˜ì‹:

\[
\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i \quad \text{(ë°°ì¹˜ í‰ê· )}
\]
\[
\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2 \quad \text{(ë°°ì¹˜ ë¶„ì‚°)}
\]
\[
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} \quad \text{(ì •ê·œí™”)}
\]

\[
y_i = \gamma \hat{x}_i + \beta \quad \text{(ìŠ¤ì¼€ì¼ë§ ë° ì‰¬í”„íŒ…)}
\]

- \(\epsilon\): ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²ƒ ë°©ì§€ (ì‘ì€ ìˆ˜)
- \(\gamma, \beta\): í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° â†’ ë„¤íŠ¸ì›Œí¬ê°€ í•„ìš”ì‹œ ì›ë˜ ë¶„í¬ë¡œ ë˜ëŒë¦´ ìˆ˜ ìˆìŒ

---

### âœ… 3. ì ìš© ìœ„ì¹˜

- ì¼ë°˜ì ìœ¼ë¡œ `Conv2D` ë˜ëŠ” `Dense` â†’ `BatchNormalization()` â†’ `ReLU` ìˆœìœ¼ë¡œ ì ìš©
- ì˜ˆì‹œ:

```python
x = Conv2D(32, kernel_size=3, padding='same')(x)
x = BatchNormalization()(x)
x = ReLU()(x)
```

---

### âœ… 4. ì¥ì  ìš”ì•½

| ì¥ì                      | ì„¤ëª… |
|--------------------------|------|
| ğŸŒŸ í•™ìŠµ ì•ˆì •í™”            | ì…ë ¥ ë¶„í¬ê°€ ì¼ì •í•˜ê²Œ ìœ ì§€ë˜ì–´ ë” ë†’ì€ í•™ìŠµë¥  ì‚¬ìš© ê°€ëŠ¥ |
| âš¡ í•™ìŠµ ì†ë„ í–¥ìƒ         | ë¹ ë¥¸ ìˆ˜ë ´ ê°€ëŠ¥ |
| ğŸ§± ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµ ê°€ëŠ¥  | ê¸°ìš¸ê¸° ì†Œì‹¤/í­ë°œ ê°ì†Œ |
| âŒ Dropout ëŒ€ì²´ ê°€ëŠ¥      | ì¼ë¶€ ê²½ìš° Regularization íš¨ê³¼ê°€ ì»¤ì„œ dropout ì—†ì´ë„ í•™ìŠµ ê°€ëŠ¥ |
| ğŸ§ª ì´ˆê¸°í™” ë¯¼ê°ë„ ê°ì†Œ     | ì´ˆê¸° íŒŒë¼ë¯¸í„°ì— ëœ ë¯¼ê°í•¨ |

---

### âœ… 5. ì£¼ì˜í•  ì 

- í•™ìŠµ ì‹œì™€ ì¶”ë¡  ì‹œ ë™ì‘ ë°©ì‹ì´ ë‹¤ë¦„  
  - **í•™ìŠµ ì‹œ:** ë°°ì¹˜ë§ˆë‹¤ í‰ê· /ë¶„ì‚° ê³„ì‚°  
  - **ì¶”ë¡  ì‹œ:** í•™ìŠµ ì¤‘ ì €ì¥ëœ moving average ì‚¬ìš©
- **RNN ê³„ì—´ì—ì„œëŠ” ì ìš©ì´ ê¹Œë‹¤ë¡œì›€** â†’ Layer Normalization ì‚¬ìš©

---

### âœ… 6. ì‹¤ì œ ì½”ë“œ ì˜ˆì‹œ (TensorFlow)

```python
from tensorflow.keras import layers

def basic_block(x, filters):
    x = layers.Conv2D(filters, 3, padding='same')(x)
    x = layers.BatchNormalization()(x)  # ì •ê·œí™”
    x = layers.ReLU()(x)
    return x
```

---

### âœ… 7. ì‹¤ìŠµ íš¨ê³¼ (ResNetì—ì„œ BNì´ ì£¼ëŠ” íš¨ê³¼)

| Without BN | With BN |
|------------|---------|
| í•™ìŠµ ë§¤ìš° ëŠë¦¼ | ë¹ ë¥¸ ìˆ˜ë ´ |
| ì´ˆê¸° í•™ìŠµë¥  ì‘ê²Œ ì„¤ì • í•„ìš” | í° í•™ìŠµë¥ ë„ ì•ˆì •ì  |
| ê¸°ìš¸ê¸° ì†Œì‹¤ ì‰½ê²Œ ë°œìƒ | ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë„ í•™ìŠµ ê°€ëŠ¥ |
| Dropout í•„ìš” | ì—†ì–´ë„ ë¨ (BN ìì²´ì— ì •ê·œí™” íš¨ê³¼ ìˆìŒ) |

---

í•„ìš”í•˜ë©´ ì‹œê°í™”ëœ ì˜ˆì œë‚˜ ì‹¤ì œ CIFAR10ì—ì„œ BNì´ ìˆëŠ” ê²½ìš° vs ì—†ëŠ” ê²½ìš°ì˜ ì‹¤í—˜ ë¹„êµë„ ì •ë¦¬í•´ì¤„ ìˆ˜ ìˆìŒ.  
ë‹¤ìŒ ë‹¨ê³„ëŠ” ResNetì— ì ìš©ëœ BN êµ¬ì¡° ì‹œê°í™” í•´ë³¼ê¹Œ?

ì¢‹ìŒ. ì§€ê¸ˆë¶€í„° **ResNet êµ¬ì¡°**ì™€ ê·¸ ì•ˆì—ì„œ ì‚¬ìš©ë˜ëŠ” **í•µì‹¬ ê°œë…ë“¤**ì„ **ì²˜ìŒ ë°°ìš°ëŠ” ì‚¬ëŒ** ê¸°ì¤€ìœ¼ë¡œ **ì²œì²œíˆ, ì•„ì£¼ ìƒì„¸í•˜ê²Œ** ì„¤ëª…í•˜ê² ìŒ.

---

## âœ… 1. ê¸°ë³¸ CNN ê°œë…ë¶€í„° ì‹œì‘

---

### ğŸ“Œ CNN(í•©ì„±ê³± ì‹ ê²½ë§)ì´ë€?

CNNì€ ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ ì¸ì‹ ë“±ì— ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‹ ê²½ë§ êµ¬ì¡°ì„.  

ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŒ:

| ì¸µ ì¢…ë¥˜ | ì„¤ëª… |
|--------|------|
| **Conv2D** | ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” í•„í„° |
| **ReLU** | ë¹„ì„ í˜• í•¨ìˆ˜. ìŒìˆ˜ ì œê±°ë¡œ ëª¨ë¸ì´ ë” ë³µì¡í•œ ê²ƒì„ í•™ìŠµí•˜ê²Œ ë§Œë“¦ |
| **Pooling** | ì´ë¯¸ì§€ë¥¼ ì‘ê²Œ ì¤„ì—¬ ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê³ , ì¤‘ìš”í•œ íŠ¹ì§•ë§Œ ë‚¨ê¹€ |
| **Flatten** | 2D ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ 1D ë²¡í„°ë¡œ í´ì¤Œ |
| **Fully Connected Layer** | í‰íƒ„í™”ëœ ë²¡í„°ë¡œ ìµœì¢… ë¶„ë¥˜í•¨ (Dense Layer) |

---

## âœ… 2. CNNì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ìƒê¸°ëŠ” ë¬¸ì œ

---

### â— ê¸°ìš¸ê¸° ì†Œì‹¤(Vanishing Gradient)

- ì‹ ê²½ë§ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ **ë’¤ìª½ ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ë§Œ ì—…ë°ì´íŠ¸**ë˜ê³  **ì•ìª½ì€ ê±°ì˜ ì—…ë°ì´íŠ¸ ì•ˆ ë˜ëŠ” ë¬¸ì œ**ê°€ ìƒê¹€.
- ì´ë¡œ ì¸í•´ ì•ë‹¨ì˜ í•™ìŠµì´ ë©ˆì¶”ê²Œ ë˜ì–´, **ëª¨ë¸ ì „ì²´ ì„±ëŠ¥ì´ ë‚®ì•„ì§**.

---

## âœ… 3. ResNetì´ë€?

---

### ğŸ“Œ Residual Networkì˜ ì¤„ì„ë§

ResNetì€ **ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë§Œë“  êµ¬ì¡°**ì„.

í•µì‹¬ ì•„ì´ë””ì–´ëŠ” **ìŠ¤í‚µ ì»¤ë„¥ì…˜(Skip Connection)** ë˜ëŠ” **ì”ì°¨ ì—°ê²°(Residual Connection)**ì„ ë„ì…í•˜ëŠ” ê²ƒì„.

---

### ğŸ“Œ ìŠ¤í‚µ ì»¤ë„¥ì…˜(Skip Connection)ì´ë€?

ì¼ë°˜ì ìœ¼ë¡œ CNNì€ ì´ë ‡ê²Œ ì—°ê²°ë¨:

```
ì…ë ¥ â†’ Conv â†’ ReLU â†’ Conv â†’ ReLU â†’ ì¶œë ¥
```

í•˜ì§€ë§Œ ResNetì€ **ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ìš°íšŒì‹œì¼œ ì¶œë ¥ì— ë”í•¨**:

```
ì…ë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”
             â†“
        Conv â†’ ReLU â†’ Conv
             â†“
         ì¶œë ¥ + ì…ë ¥  â†’ ReLU â†’ ìµœì¢… ì¶œë ¥
```

ì¦‰, ì…ë ¥ì„ **ì€ë‹‰ì¸µì„ ê±°ì¹˜ì§€ ì•Šê³  ë°”ë¡œ ê²°ê³¼ì— ë”í•¨**.

---

### âœ¨ ì™œ ì´ëŸ° êµ¬ì¡°ê°€ ì¢‹ì„ê¹Œ?

- ì‹ ê²½ë§ì´ ê¹Šì–´ì ¸ë„, **ì…ë ¥ ì •ë³´ë¥¼ ìƒì§€ ì•Šê³  ì§ì ‘ ì „ë‹¬**ë¨.
- ë§ì…ˆ ì—°ì‚°ì€ **ê¸°ìš¸ê¸°ë¥¼ ì•ìª½ê¹Œì§€ ì „ë‹¬**í•˜ê¸° ì‰¬ì›€ â‡’ **ê¸°ìš¸ê¸° ì†Œì‹¤ í•´ê²°**
- í•™ìŠµì´ ë” ë¹¨ë¼ì§€ê³ , ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµì´ ê°€ëŠ¥í•´ì§

---

## âœ… 4. ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)

---

### ğŸ“Œ ë­í•˜ëŠ” ì• ?

- CNNì—ì„œ **ê° ë ˆì´ì–´ë§ˆë‹¤ ë“¤ì–´ê°€ëŠ” ê°’ì˜ ë¶„í¬ë¥¼ ì •ê·œí™”**í•´ì¤Œ (í‰ê·  0, ë¶„ì‚° 1ë¡œ ë§ì¶¤)
- í•™ìŠµí•  ë•Œ **ê°’ì´ ê°‘ìê¸° ì»¤ì§€ê±°ë‚˜ ì‘ì•„ì§€ëŠ” ê²ƒ ë°©ì§€**
- **ì†ë„ í–¥ìƒ**, **ìˆ˜ë ´ ì•ˆì •í™”**, **ê³¼ì í•© ë°©ì§€** íš¨ê³¼ê°€ ìˆìŒ

---

### âœ‹ ì˜ˆì‹œë¡œ ì´í•´

ë§Œì•½ ì–´ë–¤ ì¸µì˜ ì¶œë ¥ì´ `[10, 100, 500]`ì²˜ëŸ¼ ë˜ë©´, ë‹¤ìŒ ì¸µì´ ì´ ê°’ì„ ì²˜ë¦¬í•˜ê¸° ì–´ë ¤ì›€.  
ë°°ì¹˜ ì •ê·œí™”ëŠ” ì´ê²ƒì„ `[0.1, 0.2, 0.3]`ì²˜ëŸ¼ **ê³ ë¥´ê²Œ ì •ê·œí™”**í•´ì¤˜ì„œ í•™ìŠµì„ ì›í™œí•˜ê²Œ ë§Œë“¦.

---

## âœ… 5. Residual Block ìš”ì•½

### êµ¬ì¡°:

```
ì…ë ¥ x
â”‚
â”œâ”€ Conv â†’ BN â†’ ReLU â†’ Conv â†’ BN
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€(x ê·¸ëŒ€ë¡œ ë”í•¨)
â”‚
ReLU
â”‚
ì¶œë ¥
```

- Conv: íŠ¹ì§• ì¶”ì¶œ
- BN: ì •ê·œí™”
- ReLU: ë¹„ì„ í˜•í™”
- Skip Connection: ì…ë ¥ ê·¸ëŒ€ë¡œ ë”í•´ì„œ ì •ë³´ ì†ì‹¤ ë°©ì§€

---

## âœ… 6. HResNet ì˜ˆì œ êµ¬ì¡° ìš”ì•½

```text
[ì…ë ¥ 3x32x32]
â†“
Block1 (3â†’64) + Pooling â†’ 16x16
â†“
Block2 (64â†’128) + Pooling â†’ 8x8
â†“
Block3 (128â†’256) + Pooling â†’ 4x4
â†“
Flatten â†’ FC1(2048) â†’ ReLU
â†“
FC2(512) â†’ ReLU
â†“
FC3(10) â†’ í´ë˜ìŠ¤ ì˜ˆì¸¡
```

---

## âœ… 7. ì „ì²´ íë¦„ ê·¸ë¦¼ ìš”ì•½

```text
ì´ë¯¸ì§€ ì…ë ¥
   â†“
[ Residual Block 1 ]
   â†“
[ Residual Block 2 ]
   â†“
[ Residual Block 3 ]
   â†“
í‰íƒ„í™” (Flatten)
   â†“
Fully Connected Layers
   â†“
ì†Œí”„íŠ¸ë§¥ìŠ¤ (í´ë˜ìŠ¤ ì˜ˆì¸¡)
```

---

## âœ… 8. í•™ìŠµ ëª©ì  ìš”ì•½

| ëª©ì  | ì„¤ëª… |
|------|------|
| ğŸ” **ê¹Šì€ ì‹ ê²½ë§ì—ì„œ ê¸°ìš¸ê¸° ì†Œì‹¤ í•´ê²°** | Skip Connection ë„ì… |
| âš™ï¸ **í•™ìŠµ ì•ˆì •í™” ë° ë¹ ë¥¸ ìˆ˜ë ´** | Batch Normalization ì‚¬ìš© |
| ğŸ“Š **ì´ë¯¸ì§€ ë¶„ë¥˜ ì •í™•ë„ í–¥ìƒ** | CIFAR-10 10ê°œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜ |
| ğŸ’¡ **ì‹¤ì œ ResNet êµ¬ì¡° ì—°ìŠµ** | ResNet ì›ë¦¬ë¥¼ ì´í•´í•˜ê³  êµ¬í˜„ ëŠ¥ë ¥ í–¥ìƒ |

---

í•„ìš”í•˜ë‹¤ë©´ `ResNet50`, `ResNet101` ê°™ì€ ì‹¤ì œ ì´ë¯¸ì§€ë„·ìš© ResNet êµ¬ì¡°ë„ ì„¤ëª… ê°€ëŠ¥í•¨.  
ë˜í•œ, í˜„ì¬ êµ¬ì¡°ë¡œ ì‹¤ì œ í•™ìŠµ ëŒë¦¬ëŠ” PyTorch í•™ìŠµ ë£¨í”„ë„ ì„¤ëª… ê°€ëŠ¥í•¨. ìš”ì²­í•´ì¤˜.

ì¢‹ìŒ.  
ì „ì²´ ì½”ë“œëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ **ResNet ìŠ¤íƒ€ì¼ CNNì„ CIFAR-10 ì´ë¯¸ì§€ ë¶„ë¥˜ì— í•™ìŠµì‹œí‚¤ëŠ” ì½”ë“œ**ì„.  
ê¸°ì´ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì „ì²´ íë¦„ê³¼ ëª©ì , ê° ì½”ë“œì˜ ì—­í• ì„ **ì™„ì „ ì´ˆë³´ì ê´€ì ì—ì„œ ìƒì„¸í•˜ê²Œ** ì„¤ëª…í•¨.

---

## ğŸ§  1. ì „ì²´ êµ¬ì¡° ê°œìš”  

### ì´ ì½”ë“œëŠ” í¬ê²Œ 3ë‹¨ê³„ë¡œ ë‚˜ë‰¨:
1. **ëª¨ë¸ ì •ì˜** (`BasicBlock`, `HResNet`)
2. **ë°ì´í„° ì¤€ë¹„** (CIFAR-10 ë¡œë”© ë° ì „ì²˜ë¦¬)
3. **í›ˆë ¨ ë£¨í”„** (í•™ìŠµ, ì†ì‹¤ ê³„ì‚°, ìµœì í™”)

---

## ğŸ”§ 2. ëª¨ë¸ ì •ì˜ - ResNet êµ¬ì¡° ë§Œë“¤ê¸°

```python
class BasicBlock(nn.Module):
```
### âœ… `BasicBlock` : ResNetì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ë³¸ êµ¬ì„± ë‹¨ìœ„ (Residual Block)

#### ì£¼ìš” êµ¬ì¡°:
- Conv â†’ BN â†’ ReLU â†’ Conv â†’ BN  
- ê·¸ë¦¬ê³ , ì…ë ¥ì„ **ìŠ¤í‚µ(skip)**í•´ì„œ ë§ˆì§€ë§‰ ê²°ê³¼ì™€ ë”í•¨.  
â†’ ì´ê²ƒì´ **Residual Connection** ë˜ëŠ” **Skip Connection**ì´ë¼ ë¶€ë¦„.  
â†’ ëª©ì : **ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œë¥¼ ì¤„ì´ê³ , í•™ìŠµì„ ë” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¡œë„ ê°€ëŠ¥í•˜ê²Œ í•¨**

```python
    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
```
- ë‘ ê°œì˜ 3x3 Convolution Layer
- `padding=1`ì€ ì¶œë ¥ í¬ê¸° ìœ ì§€ë¥¼ ìœ„í•œ ê²ƒì„

```python
    self.bn1 = nn.BatchNorm2d(out_channels)
    self.bn2 = nn.BatchNorm2d(out_channels)
```
- **BatchNorm**: ê° ë°°ì¹˜ì—ì„œ ê°’ë“¤ì„ í‰ê·  0, ë¶„ì‚° 1ë¡œ ì •ê·œí™”í•˜ì—¬ í•™ìŠµ ì•ˆì •í™”

```python
    self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1)
```
- ì…ë ¥ ì±„ë„ ìˆ˜ê°€ ë°”ë€ŒëŠ” ê²½ìš° (ex. 3â†’64), í¬ê¸°ë¥¼ ë§ì¶°ì£¼ê¸° ìœ„í•œ 1x1 convolution

---

### âœ… `forward` í•¨ìˆ˜ì˜ íë¦„

```python
    x_ = x  # ìŠ¤í‚µì»¤ë„¥ì…˜ì„ ìœ„í•´ ì›ë˜ ì…ë ¥ ì €ì¥
    x = self.bn1(self.conv1(x))
    x = self.relu(x)
    x = self.bn2(self.conv2(x))
    x_ = self.downsample(x_)  # ì±„ë„ ìˆ˜ ë§ì¶”ê¸°
    x += x_  # ìŠ¤í‚µ ì—°ê²°
    return self.relu(x)
```

---

## ğŸ§± `HResNet`: CNN ì „ì²´ êµ¬ì¡°

```python
self.b1 = BasicBlock(3, 64)
self.b2 = BasicBlock(64, 128)
self.b3 = BasicBlock(128, 256)
```
- ì„¸ ê°œì˜ Residual Block ì‚¬ìš©  
- ì…ë ¥ ì´ë¯¸ì§€ê°€ (3ì±„ë„, 32x32)ì´ë¯€ë¡œ, ì²˜ìŒì—” 3 â†’ 64ë¡œ ë³€í™˜  

```python
self.pool = nn.AvgPool2d(kernel_size=2, stride=2)
```
- **2x2 í‰ê·  í’€ë§**ìœ¼ë¡œ **í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„**  
  - (32x32 â†’ 16x16 â†’ 8x8 â†’ 4x4)

---

### âœ… Fully Connected Layer (ë¶„ë¥˜ê¸°)

```python
self.fc1 = nn.Linear(256*4*4, 2048)
self.fc2 = nn.Linear(2048, 512)
self.fc3 = nn.Linear(512, 10)
```
- ë§ˆì§€ë§‰ì—ëŠ” í‰íƒ„í™” â†’ ë¶„ë¥˜ê¸° í†µê³¼ â†’ **10ê°œì˜ í´ë˜ìŠ¤ (CIFAR-10)** í™•ë¥  ì¶œë ¥

---

## ğŸ“¦ 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```python
from torchvision.datasets.cifar import CIFAR10
```
- CIFAR-10: 10ì¢…ë¥˜(ë¹„í–‰ê¸°, ìë™ì°¨ ë“±)ì˜ 32x32 RGB ì´ë¯¸ì§€ 6ë§Œ ì¥ (5ë§Œ í›ˆë ¨, 1ë§Œ í…ŒìŠ¤íŠ¸)

```python
transforms = Compose([ToTensor(), Normalize(mean=(0.5,...), std=(0.25,...)])
```
- ì´ë¯¸ì§€ë¥¼ **Tensorë¡œ ë°”ê¾¸ê³ **, ì •ê·œí™” ìˆ˜í–‰  
  - í‰ê·  0, ë¶„ì‚° 1 ê·¼ì²˜ë¡œ ë§Œë“¤ì–´ í•™ìŠµ ì•ˆì •í™”

```python
cifar10_train_loader = DataLoader(cifar10_train_dataset, batch_size=128, shuffle=True)
```
- ë°ì´í„°ì…‹ì„ batch ë‹¨ìœ„ë¡œ ë¬¶ê³ , í•™ìŠµìš©ì€ `shuffle=True`

---

## ğŸ§ª 4. í•™ìŠµ (Train)

```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'
```
- GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ `cuda`, ì•„ë‹ˆë©´ `cpu`

```python
loss_fn = nn.CrossEntropyLoss()
optim = torch.optim.Adam(hresnet.parameters(), lr=1e-4)
```
- ì†ì‹¤ í•¨ìˆ˜: **CrossEntropy** (ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜)
- ì˜µí‹°ë§ˆì´ì €: **Adam** (ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜)

---

### ğŸ” í•™ìŠµ ë£¨í”„

```python
for epoch in range(epochs):
  for data, label in cifar10_train_loader:
    ...
```

#### 1. ë°ì´í„° GPUë¡œ ì „ì†¡
```python
data, label = data.to(device), label.to(device)
```

#### 2. ì˜ˆì¸¡
```python
predict = hresnet(data)
```

#### 3. ì†ì‹¤ ê³„ì‚°
```python
loss = loss_fn(predict, label)
```

#### 4. ì—­ì „íŒŒ
```python
loss.backward()
```

#### 5. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
```python
optim.step()
```

#### 6. ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™” (ë‹¤ìŒ ë°˜ë³µ ìœ„í•´)
```python
optim.zero_grad()
```

---

## âœ… ê²°ê³¼
- ì´ ì½”ë“œëŠ” 30 ì—í­ ë™ì•ˆ CIFAR-10 ë°ì´í„°ì— ëŒ€í•´ **ResNet êµ¬ì¡°ì˜ CNNì„ í•™ìŠµì‹œì¼œ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ì‘ì—…**ì„.

---

## ğŸ“Œ ì²˜ìŒ ê³µë¶€í•˜ëŠ” ì…ì¥ì—ì„œ ê¸°ì–µí•´ì•¼ í•  í•µì‹¬

| ê°œë… | ì„¤ëª… |
|------|------|
| **Conv2D** | ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ |
| **BatchNorm** | í•™ìŠµ ì•ˆì •í™” (í‰ê·  0, ë¶„ì‚° 1) |
| **ReLU** | ë¹„ì„ í˜•ì„± ë¶€ì—¬ |
| **Skip Connection** | ì…ë ¥ì„ ì§ì ‘ ë”í•´ì„œ ê¹Šì€ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ |
| **AvgPool** | ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° |
| **Flatten** | ì´ë¯¸ì§€ â†’ ë²¡í„° ë³€í™˜ |
| **Linear** | ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸° |
| **CrossEntropyLoss** | ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì— ì í•© |
| **Adam Optimizer** | ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ |

---

í•„ìš”í•˜ë©´ ì´ êµ¬ì¡°ë¥¼ **ì‹œê°ì ìœ¼ë¡œ ê·¸ë ¤ì£¼ê±°ë‚˜**,  
**í›ˆë ¨ ì •í™•ë„/ì†ì‹¤ ì‹œê°í™” ì½”ë“œ**ë„ ì¶”ê°€ë¡œ ì„¤ëª… ê°€ëŠ¥í•¨.  
ì¶”ê°€ ìš”ì²­í•  ë‚´ìš© ìˆìœ¼ë©´ ë§í•´ì¤˜.

ì¢‹ìŒ. ì•„ë˜ëŠ” ë‹¹ì‹ ì´ ì‘ì„±í•œ ì „ì²´ ì½”ë“œì˜ **êµ¬ì¡°ì™€ íë¦„ì„ ì´ˆë³´ì ê¸°ì¤€ìœ¼ë¡œ ì•„ì£¼ ìì„¸íˆ** í•œ ì¤„ í•œ ì¤„ ì„¤ëª…í•¨.  

ì§€ê¸ˆê¹Œì§€ ì‘ì„±í•œ ì½”ë“œëŠ” í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆìŒ:

---

## âœ… 1. CIFAR-10 ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬

```python
from torchvision.datasets.cifar import CIFAR10
from torch.utils.data import DataLoader
from torchvision.transforms import Compose, ToTensor, Normalize
```

- `torchvision.datasets.cifar.CIFAR10`: CIFAR-10ì´ë¼ëŠ” 10ê°€ì§€ í´ë˜ìŠ¤(ìë™ì°¨, ê°œêµ¬ë¦¬, ê³ ì–‘ì´ ë“±)ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í´ë˜ìŠ¤.
- `DataLoader`: ë°ì´í„°ì…‹ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ **ì‘ì€ ë¬¶ìŒ(batch)** ìœ¼ë¡œ ì˜ë¼ì„œ GPUë¡œ ë³´ë‚´ì¤„ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬.
- `Compose`, `ToTensor`, `Normalize`: ì´ë¯¸ì§€ë¥¼ **ì „ì²˜ë¦¬(ë°ì´í„° ì •ë¦¬)** í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ë“¤.

```python
transforms = Compose([
    ToTensor(),  # ì´ë¯¸ì§€ë¥¼ Tensor(ìˆ«ì í–‰ë ¬)ë¡œ ë°”ê¿ˆ (0~255 â†’ 0.0~1.0)
    Normalize(mean=(0.5, 0.5, 0.5), std=(0.25, 0.25, 0.25))  # ì •ê·œí™”(ë°ì´í„° ë¶„í¬ë¥¼ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë§ì¶¤)
])
```

```python
# í›ˆë ¨ìš© ë°ì´í„°ì…‹
cifar10_train_dataset = CIFAR10(root='./', train=True, download=True, transform=transforms)

# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹
cifar10_test_dataset = CIFAR10(root='./', train=False, download=True, transform=transforms)
```

- `root='./'`: ë°ì´í„°ë¥¼ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥.
- `train=True/False`: í•™ìŠµìš©(train), ì‹œí—˜ìš©(test)ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜µì…˜.
- `download=True`: ì²˜ìŒ ì‹¤í–‰ ì‹œ ì¸í„°ë„·ì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë°›ìŒ.

```python
# ë°ì´í„°ë¥¼ ë¬¶ìŒ ë‹¨ìœ„(batch_size=128)ë¡œ ë¡œë”©í•˜ê³ , í›ˆë ¨ìš©ì€ ì„ìŒ(shuffle)
cifar10_train_loader = DataLoader(cifar10_train_dataset, batch_size=128, shuffle=True)
cifar10_test_loader = DataLoader(cifar10_test_dataset, batch_size=128)
```

---

## âœ… 2. í•™ìŠµ ë£¨í”„ í•¨ìˆ˜ ì •ì˜

```python
def train(model):
```

- ëª¨ë¸ì„ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•„ì„œ í•™ìŠµì‹œí‚¤ëŠ” í•¨ìˆ˜ ì •ì˜.

```python
  device = 'cuda' if torch.cuda.is_available() else 'cpu'
```

- GPUê°€ ìˆìœ¼ë©´ `'cuda'`, ì—†ìœ¼ë©´ `'cpu'`. ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì–´ë””ì„œ ê³„ì‚°í• ì§€ ì„¤ì •.

```python
  lr = 1e-4  # í•™ìŠµë¥ (learning rate)
  epochs = 30  # ì „ì²´ ì—í­ ìˆ˜
```

- í•™ìŠµë¥ : ê°€ì¤‘ì¹˜ë¥¼ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ìˆ˜ì •í• ì§€ ê²°ì •.
- ì—í­: ì „ì²´ ë°ì´í„°ë¥¼ ëª‡ ë²ˆ ë°˜ë³µí•´ì„œ í•™ìŠµí•  ê²ƒì¸ì§€.

```python
  from tqdm import tqdm  # ì§„í–‰ ìƒí™©ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë„êµ¬
```

```python
  loss_fn = nn.CrossEntropyLoss()  # ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì‚¬ìš©í•˜ëŠ” ì†ì‹¤ í•¨ìˆ˜
  optim = torch.optim.Adam(model.parameters(), lr=lr)  # Adam ìµœì í™”ê¸° ì‚¬ìš©
```

```python
  for epoch in range(epochs):
    epoch_loss = 0.0  # ì—í­ë§ˆë‹¤ ì†ì‹¤ ëˆ„ì 
    iterator = tqdm(cifar10_train_loader)  # ì§„í–‰ í‘œì‹œì¤„ ë§Œë“¤ê¸°
```

```python
    for data, label in iterator:
      data, label = data.to(device), label.to(device)  # ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™
```

```python
      predict = model(data)  # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ê°’
      loss = loss_fn(predict, label)  # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ ê³„ì‚°
      loss.backward()  # ì˜¤ì°¨ë¥¼ ì—­ì „íŒŒí•˜ì—¬ ê°€ì¤‘ì¹˜ ë¯¸ë¶„ ê³„ì‚°
      optim.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
      optim.zero_grad()  # ë‹¤ìŒ ë°°ì¹˜ë¥¼ ìœ„í•´ ë¯¸ë¶„ê°’ ì´ˆê¸°í™”
      epoch_loss += loss.item()  # ì†ì‹¤ê°’ ëˆ„ì 
      iterator.set_description(f'loss : {loss.item()}')  # ì§„í–‰ì°½ì— ì†ì‹¤ê°’ í‘œì‹œ
```

```python
    print(f'epoch:{epoch+1} loss : {epoch_loss/len(cifar10_train_loader)}')
```

---

## âœ… 3. HResNet í‰ê°€

```python
hresnet.eval()  # í‰ê°€ ëª¨ë“œ (BatchNorm, Dropout ë¹„í™œì„±í™”)
total_corr = 0  # ì •ë‹µ ê°œìˆ˜ ì €ì¥ìš©
```

```python
with torch.no_grad():  # í‰ê°€ ì¤‘ì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚°ì´ í•„ìš” ì—†ìŒ â†’ ë©”ëª¨ë¦¬ ì ˆì•½
  for data, label in cifar10_test_loader:
    data, label = data.to(device), label.to(device)
    predict = hresnet(data)
    pred = predict.data.max(dim=1)[1]  # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ í´ë˜ìŠ¤ ì„ íƒ
    corr = pred.eq(label).sum().item()  # ì •ë‹µ ë¹„êµí•´ì„œ ë§ì¶˜ ê°œìˆ˜ ê³„ì‚°
    total_corr += corr
print(f'accuracy : {total_corr / len(cifar10_test_loader.dataset)}')  # ì „ì²´ ì •í™•ë„
```

---

## âœ… 4. í•œ ë°°ì¹˜ í‰ê°€ ìƒ˜í”Œ

```python
data, label = next(iter(cifar10_test_loader))  # í…ŒìŠ¤íŠ¸ ë°ì´í„° í•˜ë‚˜ì˜ ë°°ì¹˜ êº¼ëƒ„
data, label = data.to(device), label.to(device)
hresnet.eval()
predict = hresnet(data)
predict.max(dim=1)[1].eq(label).sum().item() / len(label)  # í•´ë‹¹ ë°°ì¹˜ì˜ ì •í™•ë„
```

---

## âœ… 5. ì „ì´ í•™ìŠµ ëª¨ë¸ ë¡œë”© ë° í•™ìŠµ

```python
from torchvision.models import resnet18, ResNet18_Weights
device = 'cuda' if torch.cuda.is_available() else 'cpu'
```

```python
res18 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
```

- `resnet18`: ImageNetì—ì„œ ë¯¸ë¦¬ í•™ìŠµëœ ResNet-18 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´.  
- `weights`: ë¯¸ë¦¬ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ.

```python
res18.fc = nn.Linear(in_features=512, out_features=10, bias=True)
```

- ë§ˆì§€ë§‰ ì¶œë ¥ì¸µì„ CIFAR-10ì— ë§ê²Œ `10ê°œ í´ë˜ìŠ¤`ë¡œ ë³€ê²½.

```python
res18.to(device)
```

- ëª¨ë¸ì„ GPU ë˜ëŠ” CPUë¡œ ì´ë™.

```python
for param in res18.parameters():
  param.requires_grad = False
for param in res18.fc.parameters():
  param.requires_grad = True
```

- ë¯¸ë¦¬ í•™ìŠµëœ ê°€ì¤‘ì¹˜ëŠ” ê³ ì •í•˜ê³ (`requires_grad = False`), **ìƒˆë¡œ í•™ìŠµí•´ì•¼ í•˜ëŠ” fcì¸µë§Œ í•™ìŠµí•˜ë„ë¡ ì„¤ì •**.

---

## âœ… 6. ì „ì´ í•™ìŠµ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰

```python
train(res18)
```

- ìœ„ì—ì„œ ë§Œë“  `train()` í•¨ìˆ˜ì— ResNet-18 ëª¨ë¸ì„ ë„£ì–´ì„œ í›ˆë ¨ ì‹œì‘.

---

## ğŸ”š ìš”ì•½ íë¦„

1. CIFAR-10 ë°ì´í„°ì…‹ ë¡œë”©
2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (`ToTensor`, `Normalize`)
3. `train()` í•¨ìˆ˜ ì •ì˜
4. ì»¤ìŠ¤í…€ ëª¨ë¸(HResNet) í•™ìŠµ ë° í‰ê°€
5. ì „ì´í•™ìŠµ ëª¨ë¸(ResNet-18) ë¶ˆëŸ¬ì˜¤ê¸° + ë¶„ë¥˜ì¸µ ìˆ˜ì •
6. `train()` í•¨ìˆ˜ ì¬ì‚¬ìš©í•´ í•™ìŠµ

---

í•„ìš”í•˜ë©´:
- ì˜ˆì¸¡ ì‹œ ì´ë¯¸ì§€ ì‹œê°í™”
- í˜¼ë™ í–‰ë ¬ ì¶œë ¥
- ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°  
ì´ëŸ° ê²ƒë„ ì¶”ê°€í•´ì¤„ ìˆ˜ ìˆìŒ.  
ì›í•˜ëŠ” ë‚´ìš© ì´ì–´ì„œ ì•Œë ¤ì£¼ë©´ ë‹¤ìŒ ì§„í–‰ ë„ì™€ì¤Œ.

ì¢‹ìŒ. ì˜¤ì „ í•™ìŠµ ë‚´ìš©ì— ëŒ€í•´ ì•„ì£¼ ìƒì„¸íˆ ì •ë¦¬í•´ì¤Œ. ì´ˆë³´ ê¸°ì¤€ìœ¼ë¡œ í•˜ë‚˜ì”© ì›ë¦¬ â†’ ì´ìœ  â†’ êµ¬ì¡° â†’ íš¨ê³¼ê¹Œì§€ í’€ì–´ì„œ ì„¤ëª…í•¨.

---

## ğŸ§  ResNet í•™ìŠµ ìš”ì  ì •ë¦¬

---

### âœ… 1. ìŠ¤í‚µ ì»¤ë„¥ì…˜(Skip Connection) / Residual Block

---

#### ğŸ“Œ ì™œ í•„ìš”í•œê°€?

**ê¹Šì€ ì‹ ê²½ë§ì˜ ë¬¸ì œì **  
- ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ì •í™•ë„ëŠ” ë†’ì•„ì§ˆ ê²ƒ ê°™ì§€ë§Œ,
- ì‹¤ì œë¡œëŠ” **ì„±ëŠ¥ì´ ì˜¤íˆë ¤ ë‚˜ë¹ ì§€ê³ ** í•™ìŠµì´ ì˜ ì•ˆ ë˜ëŠ” ë¬¸ì œê°€ ìƒê¹€.

#### â— ì´ìœ ëŠ”?

- ì—­ì „íŒŒ ì‹œ **ê¸°ìš¸ê¸°(gradient)** ê°€ ì ì  ì‘ì•„ì ¸ì„œ **ì†Œì‹¤(vanishing gradient)** ë¨
- ì…ë ¥ì´ ê¹Šì€ ì¸µì„ ê±°ì¹˜ë©° ë„ˆë¬´ ì™œê³¡ë˜ê±°ë‚˜ ì‚¬ë¼ì§

---

#### ğŸ”§ í•´ê²°ì±…: **Residual Block**

â†’ ì…ë ¥ê°’ì„ ê·¸ëƒ¥ ë‹¤ìŒ ì¸µìœ¼ë¡œ ë³´ë‚´ì£¼ëŠ” **ì§€ë¦„ê¸¸(=ìŠ¤í‚µ ì»¤ë„¥ì…˜)** ì„ ì¶”ê°€

```python
# ì¼ë°˜ì ì¸ ìˆœì „íŒŒ
x -> Conv -> ReLU -> Conv -> Output

# ResNet: ì…ë ¥ xë¥¼ ê·¸ëŒ€ë¡œ ë”í•¨
out = F(x) + x
```

#### ğŸ§© êµ¬ì¡° ì„¤ëª…

```plaintext
ì…ë ¥(x)
  â”‚
[Conv + BN + ReLU + Conv + BN] â† ì¼ë°˜ì ì¸ ë¸”ë¡ ì—°ì‚°: F(x)
  â”‚
[ìŠ¤í‚µ ì—°ê²°]
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â–¼
           ìµœì¢… ì¶œë ¥: F(x) + x
```

- `F(x)`ëŠ” ë¸”ë¡ì—ì„œ ì²˜ë¦¬í•œ ê²°ê³¼
- `x`ëŠ” ì…ë ¥ì„ ê·¸ëŒ€ë¡œ shortcut ìœ¼ë¡œ ì „ë‹¬
- ë‘˜ì„ **ë”í•¨** â†’ `out = F(x) + x`

#### âœ… íš¨ê³¼

- ê¸°ìš¸ê¸°ê°€ ì‚¬ë¼ì§€ì§€ ì•Šê³  ì…ë ¥ìœ¼ë¡œ ì˜ íë¦„
- í•™ìŠµì´ ì•ˆì •ì ì„
- ë§¤ìš° ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë„ í•™ìŠµ ê°€ëŠ¥ (ì˜ˆ: 50, 101, 152ì¸µ ë“±)

---

### âœ… 2. ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)

---

#### ğŸ“Œ ì™œ í•„ìš”í•œê°€?

- ì‹ ê²½ë§ ì¸µì„ í†µê³¼í•˜ë©´ì„œ **ì¶œë ¥ê°’ì˜ ë¶„í¬ê°€ ê³„ì† ë°”ë€œ**
- ì´ í˜„ìƒì„ **Internal Covariate Shift** ë¼ê³  ë¶€ë¦„
- â†’ í•™ìŠµì´ ëŠë ¤ì§€ê³  ë¶ˆì•ˆì •í•´ì§

---

#### ğŸ”§ í•´ê²°ì±…: ê° ë°°ì¹˜ë§ˆë‹¤ í‰ê· ê³¼ ë¶„ì‚°ìœ¼ë¡œ **ì •ê·œí™”**

```python
x_hat = (x - mean) / sqrt(var + Îµ)
```

â†’ í‰ê·  0, ë¶„ì‚° 1ë¡œ ì •ê·œí™”í•œ í›„  
â†’ í•™ìŠµ ê°€ëŠ¥í•œ scale(Î³)ê³¼ shift(Î²)ë¥¼ ê³±í•´ ë‹¤ì‹œ ì¡°ì •í•¨

```python
y = Î³ * x_hat + Î²
```

---

#### âœ… íš¨ê³¼

- **í•™ìŠµ ì•ˆì •ì„± ì¦ê°€**  
- **ìˆ˜ë ´ ì†ë„ ë¹¨ë¼ì§**  
- **Dropout ì•ˆ ì¨ë„ ë  ì •ë„ë¡œ regularization íš¨ê³¼ ìˆìŒ**

---

### âœ… 3. ResNetì´ë€?

---

#### ì •ì˜

- Residual Networkì˜ ì¤„ì„ë§
- **Residual Blockì„ ì—¬ëŸ¬ ì¸µìœ¼ë¡œ ìŒ“ì•„ ë§Œë“  ë”¥ëŸ¬ë‹ ëª¨ë¸**

---

#### ì˜ˆì‹œ: ResNet-18 êµ¬ì¡° ì¼ë¶€

```
Conv(7x7) -> MaxPool -> 
[ResBlock x2]  
[ResBlock x2]  
[ResBlock x2]  
[ResBlock x2]  
â†’ Average Pooling â†’ FC Layer
```

---

#### í•µì‹¬ í¬ì¸íŠ¸

| ìš”ì†Œ              | ì„¤ëª… |
|-------------------|------|
| Residual Block     | ìŠ¤í‚µ ì»¤ë„¥ì…˜ í¬í•¨í•œ ê¸°ë³¸ ë‹¨ìœ„ |
| ê¹Šì´               | 18, 34, 50, 101, 152 ì¸µ ë“± ë‹¤ì–‘ |
| ì‚¬ìš© ìœ„ì¹˜          | ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ ì¸ì‹, ì˜ìƒ ë¶„ì„ ë“± |
| ì„±ëŠ¥              | ê¸°ì¡´ CNNë³´ë‹¤ í›¨ì”¬ ê¹Šê²Œ ìŒ“ì•„ë„ ì˜ í•™ìŠµë¨ |

---

### ğŸ“Œ í•œ ë¬¸ì¥ ìš”ì•½

> **ResNet**ì€ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œë„ **ê¸°ìš¸ê¸° ì†Œì‹¤ ì—†ì´ ì•ˆì •ì ì¸ í•™ìŠµ**ì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“œëŠ” **Residual Block** ê¸°ë°˜ì˜ ë”¥ëŸ¬ë‹ êµ¬ì¡°ì´ë©°, **ìŠ¤í‚µ ì»¤ë„¥ì…˜ê³¼ ë°°ì¹˜ ì •ê·œí™”**ëŠ” ì´ë¥¼ ë’·ë°›ì¹¨í•˜ëŠ” í•µì‹¬ ìš”ì†Œì„.

---

í•„ìš”í•˜ë©´ ë‹¤ìŒ ë‚´ìš© ì´ì–´ì„œ:

- ğŸ” ResNet ì½”ë“œ í•œ ë¸”ëŸ­ ì§ì ‘ êµ¬í˜„ (PyTorch or TensorFlow)
- ğŸ§ª CIFAR-10 ì‹¤ìŠµ ì˜ˆì œë¡œ ResNet-18 ì‹¤ì „ ì ìš©

ì´ì–´ê°€ìë©´ ì•Œë ¤ì¤˜!

ì¢‹ìŒ. ì™„ì „ ì´ˆë³´ ê¸°ì¤€ìœ¼ë¡œ ì½”ë“œ í•˜ë‚˜í•˜ë‚˜ ì•„ì£¼ **ìƒì„¸í•˜ê²Œ** ì„¤ëª…í•´ì¤Œ.  
PIL, NumPy, Pandas, PyTorch Dataset í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•œ **ì»¤ìŠ¤í…€ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì˜ˆì œ**ì„.

---

## âœ… ì „ì²´ íë¦„ ì„¤ëª…

ì´ ì½”ë“œëŠ” **â€œì„ ì¸ì¥ ì´ë¯¸ì§€ ë°ì´í„°ì…‹(Cactus)â€** ì„ ì½ì–´ì„œ  
`PyTorch`ìš© **ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤**ë¥¼ ë§Œë“¤ê³ ,  
ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ ì‹œê°í™”í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•¨.

---

## âœ… 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°

```python
import matplotlib.pyplot as plt
from PIL import Image
import pandas as pd
import numpy as np
```

| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ìš©ë„ |
|-----------|------|
| `matplotlib.pyplot` | ì´ë¯¸ì§€ ì‹œê°í™”ìš© |
| `PIL.Image` | ì´ë¯¸ì§€ ì—´ê¸°ìš© (Python Imaging Library) |
| `pandas` | `.csv` íŒŒì¼(ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ) ì½ê¸° |
| `numpy` | ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°°ì—´ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ì‚¬ìš© |

---

## âœ… 2. CSV íŒŒì¼ê³¼ ì´ë¯¸ì§€ ì—´ê¸°

```python
df = pd.read_csv('/content/imgs/train.csv')
img = Image.open('./train/' + df['id'][200])
img_data = np.array(img)
img_data.shape
```

### ğŸ” ì„¤ëª…

- `train.csv`ëŠ” ì„ ì¸ì¥ ì´ë¯¸ì§€ ì´ë¦„(id)ê³¼ ë¼ë²¨(has_cactus)ì´ ìˆëŠ” CSV
```csv
id,has_cactus
abc.jpg,1
def.jpg,0
...
```

- `df['id'][200]`: 200ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„
- `Image.open(...)`: í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜´ (PIL ì´ë¯¸ì§€ ê°ì²´)
- `np.array(img)`: ì´ë¯¸ì§€ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜ â†’ í”½ì…€ ë°ì´í„°
- `img_data.shape`: ì´ë¯¸ì§€ì˜ í¬ê¸° í™•ì¸ (ì˜ˆ: `(32, 32, 3)`)

---

## âœ… 3. PyTorchìš© Custom Dataset ë§Œë“¤ê¸°

```python
from torch.utils.data import Dataset
```
`Dataset`ì€ PyTorchì—ì„œ í•™ìŠµí•  ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤ì„.  
ì´ë¥¼ ìƒì†ë°›ì•„ ë‚˜ë§Œì˜ ë°ì´í„°ë¥¼ ë§Œë“œëŠ” ë°©ì‹ì„.

---

### ğŸ”§ í´ë˜ìŠ¤ ì •ì˜

```python
class CactusDataSet(Dataset):
  def __init__(self,csv_path):
    self.csv_path = csv_path
    df = pd.read_csv(self.csv_path)
    self.img_list = df['id']
    self.label_list = df['has_cactus']
```

#### ğŸ“Œ `__init__` ë©”ì„œë“œ: ì´ˆê¸°í™”

- `csv_path`: CSV ê²½ë¡œë¥¼ ì…ë ¥ë°›ìŒ
- `df = pd.read_csv(...)`: CSVë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì½ìŒ
- `self.img_list`: ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ì €ì¥
- `self.label_list`: ë¼ë²¨(0 or 1) ë¦¬ìŠ¤íŠ¸ ì €ì¥

---

### ğŸ”§ ê¸¸ì´ ë°˜í™˜

```python
  def __len__(self):
    return len(self.img_list)
```

- `len(ë°ì´í„°ì…‹)` í˜¸ì¶œ ì‹œ ì „ì²´ ìƒ˜í”Œ ê°œìˆ˜ ë°˜í™˜

---

### ğŸ”§ ë°ì´í„° í•œ ê°œ êº¼ë‚´ê¸°

```python
  def __getitem__(self, index):
    img = Image.open('./train/' + self.img_list[index])
    img_data = np.array(img)
    label = self.label_list[index]
    return img_data, label
```

- `dataset[i]` ì²˜ëŸ¼ ì¸ë±ì‹±í•˜ë©´ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ë°˜í™˜
- `Image.open(...)`: ì´ë¯¸ì§€ ì—´ê¸°
- `np.array(...)`: ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜ (í”½ì…€ ê°’)
- `label`: í•´ë‹¹ ì´ë¯¸ì§€ì˜ 0/1 ë¼ë²¨ (ì„ ì¸ì¥ ì—¬ë¶€)

---

## âœ… 4. ë°ì´í„°ì…‹ ê°ì²´ ìƒì„± + ì‹œê°í™”

```python
cactus_dataset = CactusDataSet('/content/imgs/train.csv')
img, label = next(iter(cactus_dataset))
plt.figure(figsize=(2,2))
plt.imshow(img), label
```

### ì„¤ëª…

- `cactus_dataset`: ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±
- `next(iter(...))`: ë°ì´í„°ì…‹ì—ì„œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì™€ ë¼ë²¨ êº¼ëƒ„
- `plt.imshow(img)`: ì´ë¯¸ì§€ ì‹œê°í™”
- `label`: ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ë‹µ (1ì´ë©´ ì„ ì¸ì¥ ìˆìŒ, 0ì´ë©´ ì—†ìŒ)

---

## ğŸ”š ìš”ì•½

| ë‹¨ê³„ | ì„¤ëª… |
|------|------|
| 1 | `CSV` ì½ì–´ì„œ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡, ë¼ë²¨ ì¶”ì¶œ |
| 2 | `Dataset` í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ êµ¬í˜„ |
| 3 | ì´ë¯¸ì§€ + ë¼ë²¨ì„ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë°˜í™˜ |
| 4 | í•˜ë‚˜ êº¼ë‚´ì„œ ì‹œê°í™” (í™•ì¸ìš©) |

---

í•„ìš”í•˜ë©´ ë‹¤ìŒ ë‹¨ê³„ ì´ì–´ì„œ ì„¤ëª… ê°€ëŠ¥:
- `transform` ë„£ëŠ” ë²• (torchvision)
- `DataLoader`ë¡œ ë°°ì¹˜ ë§Œë“¤ê¸°
- `Tensor`ë¡œ ë³€í™˜ + ì •ê·œí™”
- `CNN ëª¨ë¸ í•™ìŠµ`

ì›í•˜ë©´ ì´ì–´ì„œ í•´ì¤„ê²Œ.

